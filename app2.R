##################################################################################################
##################################################################################################
############################# Codeless Robyn UI - Source code ####################################
##################################################################################################
##################################################################################################

# Please ensure that the libraries listed below are all installed successfully on your machine prior to running. 
# There should be no need to edit the code
# See the readme on Github for instructions on preparing your system to run this application
# 

library(shiny)
library(dplyr)
library(patchwork)
library(shinycssloaders)
library(DT)
library(data.table) 
library(stringr) 
library(lubridate) 
library(doParallel) 
library(foreach) 
library(glmnet) 
library(car) 
library(StanHeaders)
library(prophet)
library(ggplot2)
library(gridExtra)
library(grid)
library(ggpubr)
library(see)
library(PerformanceAnalytics)
library(nloptr)
library(minpack.lm)
library(rPref)
library(reticulate)
library(rstudioapi)
library(shinyjs)
library(shinyBS)
library(dbplyr)
library(tidyr)
library(viridis)
library(ggcorrplot)
library(gghighlight)
library(corrr)
library(veccompare)
library(Robyn) # remotes::install_github("facebookexperimental/Robyn/R")

#conda_create("r-reticulate",python_version = '3.9') # must run this line once
#conda_install("r-reticulate", "nevergrad", pip=TRUE)  #  must install nevergrad in conda before running Robyn
# use_python("/Users/gufengzhou/Library/r-miniconda/envs/r-reticulate/bin/python3.6") # in case nevergrad still can't be imported after installation, please locate your python file and run this line

tryCatch(py_discover_config(),
error = function(e) {use_condaenv("r-reticulate",required = TRUE)},
warning = function(w){},
finally = function(f){}
)
#if running from button click this
tryCatch(script_path <<- str_sub(rstudioapi::getActiveDocumentContext()$path, start = 1, end = max(unlist(str_locate_all(rstudioapi::getActiveDocumentContext()$path, "/")))),
         warning = function(w){},
         error = function(e){},
         finally = function(f){}
)


################################################################
#### load data & scripts

#########
# Define UI ----
ui <- fluidPage(
  shinyjs::useShinyjs(),
  tags$head(
    # this changes the size of the popovers
    #need to use hyphen not underscore
    tags$style(type = 'text/css', '.popover{max-width:60%;max-height:200%;}','.datepicker {z-index:99999 !important;}',
    '.navbar-default {
      background-color: DFDFD6 !important;}'
    )
  ),
  titlePanel(HTML('<img src="https://facebookexperimental.github.io/Robyn/img/robyn_logo.png" alt="Logo" width = 50 height = 40> Codeless Robyn - An Open-Source Marketing Mix Model Development UI'),
             windowTitle = 'Codeless Robyn'),

    navbarPage(title = '',
      tabPanel(title = 'Getting Started',
               fluidRow(
                 column(
                   width=12,
                   headerPanel(
                     h3("Welcome to Codeless Robyn - An Open-Source Marketing Mix Model Development UI Alpha where our goal is to democratize access to MMM and encouraging good marketing practices through data and science", 
                        style = "font-weight: 500; line-height: 1.1; 
                  color:blue;")))
                   ),
               br(),
               br(),
                   fluidRow(
                     column(width = 12,
                            headerPanel(
                              h3(a('To discover more about Project Robyn, please click here visit our website and github repository',href = 'https://facebookexperimental.github.io/Robyn/',target = '_blank'),
                                 style = 'font-weight:300;line-height:1.1;color:black')
                            ))
                   ),
               br(),
               br(),
               
                   fluidRow(
                     column(width = 12,
                            headerPanel(
                              h3('There a few key tips to remember when using this alpha tool. With them, we hope you will be able to quickly overcome any issues, but if you run into any issues that block your progress please post an issue on the private github repository you were invited to and we will get to it ASAP.',
                                 style = 'font-weight:100;line-height:1.1;color:black')
                            ),
                            

                            )
                            ),
               br(),
               br(),
               hr(),
               fluidRow(
                 column(width = 12, align = 'center',
                        headerPanel(h2('Important Information to Remember')))
               ),
               br(),
               fluidRow(
                 column(width = 4, offset = 0,
                        headerPanel(
                          h4('This tool will store finalized variables between sessions. So if you close the app, or it crashes, try starting the app back up and resuming at the tab you left off at.')
                        )),
                 column(width = 4, offset = 0.33,
                        headerPanel(h4('Anytime you see a question mark icon, click it to learn more about best practices and clear up any questions you have about understanding and interpreting different aspects of the tool.'))
               ),
               column(width = 4, offset = 0.66,
                      headerPanel(h4('Reach out to your Facebook Marketing Science Partner if all else fails. Please keep us informed of any fast feedback you have, and as you go through the tool think about what features if any would improve your experience with the tool.'))
               ),
      ),
      br(),
      br(),
      fluidRow(
        column(width = 6, 
               #offset = -0.33, 
               align = 'center',
               headerPanel(h4('If the tool ever seems stuck, or you need to cancel a currently running action return to the RStudio UI and click the stop-sign button at the top-right of the console.'))
      ),
      column(width = 6, 
             align = 'center',
             headerPanel(h4('To reset all data and inputs, return to the RStudio UI and either click the broom icon above the environment window, or run the code "rm(list=ls()); gc()"'))
             )
      )
      ),        
      navbarMenu(title = 'Create a New Model',
      tabPanel((title = 'Data Input and Variable Assignment'),
        sidebarLayout(
          sidebarPanel(
            fileInput('data_file', label = h4('Choose CSV File containing data, with column names in first row ',
                                              tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                              bsButton("data_file_popover", label = "", icon = icon("question"), style = "info", size = "extra-small")),
                                              accept = '.csv'),
            bsPopover(id = 'data_file_popover', title = 'Choosing a CSV File for your main dataset',
                      content = paste0('Upload your dataset here. The file must be of .csv type, and should contain at least a column for a date variable, '
                      ,'and an independent variable such as revenue or conversions. For an example of what this file could look like, see the de_simulated_data.csv '
                      ,'file in the ', 
                      a('github repository. ', href = 'https://github.com/facebookexperimental/Robyn/blob/master/source/de_simulated_data.csv', target = '_blank'),
                      'Additionally, for more detailed information on this step please refer to the ',
                      a('step by step guide.', href = 'https://facebookexperimental.github.io/Robyn/docs/step-by-step-guide#load-data', target = '_blank')
                      ),
                      placement = 'right', trigger = 'focus', option = list(container = 'body')),
            fileInput('holiday_file', label = h4('Choose CSV File containing holiday info',
                                             tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                             bsButton("holiday_file_popover", label = "", icon = icon("question"), style = "info", size = "extra-small")),
                                             accept = '.csv'),
            bsPopover(id = 'holiday_file_popover', title = 'Choose a file that contains holiday data for your region of choice',
                      content = paste0('Upload your dataset containing holiday data. If you do not have a separate file',
                      ', in the github repository there is a file called holidays.csv that you can access ',
                      'here containing holiday data going back and forward many years. Click ',
                      a('here.', href = 'https://github.com/facebookexperimental/Robyn/blob/master/source/holidays.csv'),
                      ' If you do have your own holiday file, ensure the formatting is the same as this file.'),
                      placement = 'right', trigger = 'focus', option = list(container = 'body')),
            selectInput('dep_var', label = h4('Input Dependent Variable Name',
                                            tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                            bsButton("dep_var_popover", label = "", icon = icon("question"), style = "info", size = "extra-small")
            ), choices = '', selectize = F),
            bsPopover(id = 'dep_var_popover', title = 'Dependent Variable Name',
                      content = 'Input the column name of your dependent variable here. It must correspond to conversion or revenue',
                      placement = 'right', trigger = 'focus', option = list(container = 'body')),
            selectInput('dep_var_type',label = h4('Dependent Variable Type',
                                            tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                            bsButton("dep_var_type_popover", label = "", icon = icon("question"), style = "info", size = "extra-small"))
                        ,choices = list('revenue', 'conversion')),
            bsPopover(id = 'dep_var_type_popover', title = 'Dependent Variable Type',
                      content = 'Make a selection on the type of your dependent variable between conversion or revenue',
                      placement = 'right', trigger = 'focus', option = list(container = 'body')),
            selectInput('date_var', label = h4('Input DATE variable name',
                                             tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                             bsButton('date_var_popover', label = "", icon = icon("question"), style = "info", size = "extra-small")
                      ),choices = '', selectize = F),
            bsPopover(id = 'date_var_popover', title = 'Date Variable Name Input',
                      content = paste0('Input name of your date variable. <b>Note - Date variable must be in format "YYYY-mm-dd"</b>',
                                '. Typically this will be either daily or weekly data. Consider testing both, but having more granular daily data may help the model fit.'),
                      placement = 'right', trigger = 'focus', options = list(container = 'body')),
            textInput('date_format_var',label = h4('Input DATE format',tags$style(type = 'text/css','#q2{vertical-align:top;}'),
                                                   bsButton('date_format_popover',label = '', icon = icon('question'), style = 'info',size = 'extra-small')
                                                   ),value = '%Y-%m-%d'),
            bsPopover(id = 'date_format_popover',title = 'Inputting the format of your date variable',
                      content = paste('To ensure that the date variable formatting is ingested correctly we must specify the formatting. In practice, this will look something like %Y-%m-%d, which corresponds to YYYY-mm-dd or a date like 2021-1-30. If your data is formatted like month/day/year, then your format will be %m/%d/%Y an example of which would be 12/27/2020 etc.',
                                      'Since we are dealing with daily data at the smallest here, our formatting will use the letters lowercase m (month), lowercase d (day), and uppercase Y (Year) to specify the format. If you are having trouble specifying the correct format, it may be easier to reformat your data to the default format of %Y-%m-%d.',
                                      sep = '<br><br>'
                                      ),
                      placement = 'right', trigger = 'focus', options = list(container = 'body')),
            numericInput('num_media', label = h4('Number of Paid Media Channels to Include',
                                                 tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                                 bsButton("paid_media_vars_popover", label = "", icon = icon("question"), style = "info", size = "extra-small"))
                         ,step = 1, min = 1, value = 1),
            bsPopover(id = 'paid_media_vars_popover', title = 'Setting up your Paid Media Variables', 
                      content = paste('For each Paid Media Channel you plan to measure, you will need to specify which variable names correspond to which channels. ',
                                       'First, Identify the total number of Paid Media Variables and input that into the Text Box under Number of Paid Media Variables. ',
                                       'Next, ensure that where possible, you have both a spend variable and a variable that is more closely tied to action. ',
                                       'For example, let us use Facebook as an example and use Facebook Impressions and Facebook Spend as our variables corresponding to that channel. ',
                                       'After we hit the Initialize Media & Baseline Variable Inputs button, a number of input fields will appear prompting you to input in the left box the action variable e.g. Impressions or Clicks, and in the right box the spend variable for the same channel',
                                       'The reason for needing both variables is due to the complex relationship between spend and a variable like impressions. ',
                                       'In many cases, these variables do not have a 1-1 relationship, and instead the relationship is better fit by a curve than by a straight line. ',
                                       paste0('In Robyn, we use the ',a('Michaelis-Menten function', href = 'https://en.wikipedia.org/wiki/Michaelis%E2%80%93Menten_kinetics', target = '_blank'), ' to model this relationship. Ensure that your variable names are case-sensitive and correctly spelled corresponding to columns in the dataset. '),
                                      'A decent rule-of-thumb for which paid media channels to include would be to say that channels below ~2% of total spend could be grouped together in ways that makes logical sense due to similarities between the channels, and channels that could be broken up into logical breaks that represent >2% each should explore those breaks.',
                                      'For example, if we had 3 different programmatic channels that each made up 1.5% of total spend, we could consider combining them into a single variable. Additionally, if a channel like Facebook had 25% of the budget with two distinct strategies - Brand Messaging and Direct Response Messaging equally receiving half of that spend, we could consider breaking that up into two separate variables. ',
                                      'Another thing to watchout for - Some channels have pay systems that directly correspond to how much of the dependent variable they are driving. In some cases, these variables may be too highly correlated with the dependent variable for it to make logical sense including in the model. Keep a close watch for any variables that have very strong correlations with the dependent variable.',
                                       paste0('For more information about this step, see the ', a('step-by-step guide.', href = 'https://facebookexperimental.github.io/Robyn/docs/step-by-step-guide/#set_mediavarname-and-set_mediaspendname')),
                                      sep = '<br><br>'
                                       ),
                      placement = 'right', trigger = 'focus', options = list(container = 'body')),
            numericInput('num_organic_media', label = h4('Number of Organic Media Channels to Include',
                                                 tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                                 bsButton("organic_media_vars_popover", label = "", icon = icon("question"), style = "info", size = "extra-small"))
                         ,step = 1, min = 0, value = 0),
            bsPopover(id = 'organic_media_vars_popover',title = 'Setting up your Organic Media Variables',
                      content = 'In order to more accurately capture the impact of Organic Media variables, we treat them similar to paid media variables by giving them adstocks and saturation curves. This ensures that we capture any latent effect of organic media.'
                      ),
            numericInput('num_context', label = h4('Number of Contextual (Non Paid Media, Non Organic Media) Variables',
                                                 tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                                 bsButton("context_vars_popover", label = "", icon = icon("question"), style = "info", size = "extra-small"))
                         ,step = 1, min = 0, value = 0),
            bsPopover(id = 'context_vars_popover', title = 'Setting up your Contextual Variables',
                      content = paste('Proper representation of Contextual Variables (i.e. your variables that are not Paid/Organic Media Variables) can have a substantial impact on an MMMs ability to fit the data, as well as explain the trends a business sees.',
                                      'Since there are really an infinite number of different variables you could test to see if they have an impact on your dependent variable, it can help to prioritize some variables that are most commonly used in MMM.',
                                      'Below we will highlight a few areas where many data scientists may include variables from in their models. This is not an exhaustive list, but should be a decent starting point. Remember that any variable that could have an impact on business performance could be important in helping increase the fit of the model, no matter what it is.',
                                      '<b>1) Organic/Earned Media/Owned Media</b> - Many brands have significant organic/owned media presences where events like posts, email blasts, or public relations buzz can lead to consideration.',
                                      '<b>2) Advertiser-specific data</b> - For example - pricing changes, dates of promotions/sales, product launches, changes in shipping availability, etc.',
                                      '<b>3) Competitor info</b> - For example, Google Search Trends data looking at your competitors search volume index over time, or other competitor behavior that leads to a significant change in the market.',
                                      '<b>4) Macroeconomic Trends</b> - Unemployment Rates, Consumer Confidence, other data can help explain consumer investment trends in certain categories of goods',
                                      paste0('<b>5) Unique Time Periods</b> - Many advertisers were impacted in differing ways by unpredictable events like the Covid-19 Pandemic. ', a('Click here for a Facebook IQ article', href = 'https://www.facebook.com/business/news/insights/5-ways-to-adjust-marketing-mix-models-for-unexpected-events', target = '_blank'), ' highlighting some ways that advertisers can build models that are accounting for unprecented times.'),
                                      '<b>6) Geographic specific data</b> - If your business is affected differently in different regions, for example by something like weather that can be an important factor to include.',
                                      'Oftentimes, an advertiser may see a model that fits well overall, but very poorly in specific circumstances. Improving the coverage of the models contextual variables may help address some of those issues when they arise.',
                                      'As with the paid media variables, you will need to enter the total number of contextual variables you would like to include in the model into the  Number of Contextual Variables box below. After you have the number of variables entered and press the Initialize button, you will need to enter the column names that correspond to each of your Contextual variables as well as the sign that you would like the model to adopt for that variables and tell the tool whether that variable is a factor (i.e. categorical, indicator) or not.',
                                      'For some variables (e.g. competitor trends) you may know for certain that the variable will have a negative affect on your sales as it increases so you can set the sign to negative. For other variables the effect may be clearly positive, or if unsure, simply leave the sign setting as Default.',
                                      '<b> An important rule of thumb to answer the question - How much data do we need? Can be answered by roughly using 1:10 variables to observations. In other words, if you have 10 independent variables then you should have at least 100 observations. Remember that the variables that are generated via Prophet for seasonality, trend, etc. count towards this. More on Prophet later. This showcases again how more fine grain data has advantages in terms of ability to detect effect sizes for more variables or with less data.',
                                      sep = '<br><br>'), placement = 'right', trigger = 'focus', options = list(container = 'body')
                      ),
            actionButton('init_var_input',label = 'Initialize Media & Contextual Variable Inputs')
          ),
          mainPanel(
            dataTableOutput('data_tbl', width = '1000'),
            dataTableOutput('hol_tbl', width = '1000'),
            br(),
            br(),
            uiOutput('var_assignment_descipt'),
            br(),
            uiOutput('media_vars'),
            uiOutput('org_media_vars'),
            uiOutput('context_vars'),
            uiOutput('finalize_vars'),
            uiOutput('fin_var_assign_popover_output'),
            br(),
            uiOutput('vars_finalized')
          )
        )
      ),
      tabPanel((title = 'Exploratory Data Analysis'),
               fluidRow(
                 column(
                   width=12,
                   actionButton('EDA_initiate', label = 'Click to Initiate Exploratory Data Analysis incl. Auto Generated Recommendations'),
                   headerPanel(  
                   h3("Recommendations Based on Exploratory Data Analysis", 
                        style = "font-family: 'Lobster';
                        font-weight: 500; line-height: 1.1; 
                      color: #990000;")
                   ),
                   htmlOutput('print_message_1'),
                   htmlOutput('print_message_2'),
                   htmlOutput("print_message_3a"),
                   htmlOutput("print_message_3b"),
                   htmlOutput("print_message_4"),
                   fluidRow(
                     column(12,
                            hr(style = "border-top: 1px solid #000000;"),
                            headerPanel(
                              h3("Refer to the charts below for more detail", 
                                 style = "font-family: 'Lobster';
                            font-weight: 500; line-height: 1.1; 
                            color: #000080;")
                            ),
                            tabsetPanel(
                              tabPanel("Chart 1", plotOutput("ggplot1")), 
                              tabPanel("Chart 2a-2d",
                                       splitLayout(cellWidths = c('50%','50%'),
                                                   plotOutput("ggplot2a"),
                                                   plotOutput("ggplot2b")
                                       ),
                                       splitLayout(cellWidths = c('50%','50%'),
                                                   plotOutput("ggplot2c"),
                                                   plotOutput("ggplot2d")
                                       )
                              ), 
                              tabPanel("Chart 3a", plotOutput("ggplot3a")),
                              tabPanel("Chart 3b", plotOutput("ggplot3b")),
                              tabPanel("Chart 4", plotOutput("ggplot4")),
                              tabPanel("Chart 5",
                                       fluidRow(
                                         column(width = 3,
                                                selectInput('granularity',label = h4('Data Granularity',
                                                                                     tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                                                                     bsButton("granularity_popover", label = "", icon = icon("question"), style = "info", size = "extra-small"))
                                                            ,choices = list('daily', 'weekly')),
                                                bsPopover(id = 'granularity_popover', title = 'Data Granularity', 
                                                          content = 'Make a selection between daily or weekly based on the granularity of your data',
                                                          placement = 'right', trigger = 'focus', option = list(container = 'body'))
                                         ),
                                         column(width = 3, 
                                                uiOutput('var_to_plot_input')
                                                )
                                       ),
                                       fluidRow(
                                         plotOutput("ggplot5")
                                       )
                              )
                            )
                     )
                   )
                 )
               )
      ),
      tabPanel(title = 'Model Tuning',
               sidebarLayout(
                 sidebarPanel(width = 5,
                   selectInput('adstock_selection', label = h4('Select Adstock Distribution',
                                                                 tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                                                 bsButton("adstock_selection_popover", label = "", icon = icon("question"), style = "info", size = "extra-small")),
                               choices = c('geometric','weibull'), selected = 'geometric', selectize = F),
                   bsPopover(id = 'adstock_selection_popover', title = 'Selecting a distribution for your Adstocks', 
                             content = paste('Adstocks are a critical part of building Marketing Mix Models. Adstocks can be complex to understand but essentially they are a measure of how much media effect carries over from Period X to Period X+1.',
                                             paste0('In Robyn, there are two different distributions you can choose to develop your adstocks for each paid media channel. These two distributions are ',a('Geometric',href = 'https://en.wikipedia.org/wiki/Geometric_distribution', target = '_blank'), ' and ', a('Weibull', href = 'https://en.wikipedia.org/wiki/Weibull_distribution', target = '_blank'), ' distributions.'),
                                             'The distribution you choose is important because there are different hyperparameters for them. The geometric adstock has one hyperparameter - Theta, which represents the decay rate from period X to period X+1 in a generic way. So for example, if we had a channel with an theta value of 0.9, that would mean that only 90% of the effect from period X would carry over into period X+1. And then 90% of the value of X+1 (or 81% of the value of X) would carry over to X+2, and so on.',
                                             'With Weibull distributions, it is a little more flexible since it has two hyperparameters - shape and scale, whereas geometric only has theta. In the Weibull distribution, Shape is the parameter that controls the decay shape between exponential and s-shape. The larger, the more s-shape, meaning the carryover effect will be stronger and last longer in time. the smaller, the more L-shape, meaning the weaker the carryover effect, and the shorter its effect lasts in time. Scale is the parameter that controls the position of the decay inflection point. Recommended bounds are between 0 and 0.1. This is because scale can inflate adstocking half-life siginificantly.',
                                             'The additional hyperparameter used in Weibull adstocking can help allow the adstocks to better represent the reality through increased flexibility. At times, this increased flexibility can lead to an increased fit of the model. With that, an extra hyperparameter will also lead to longer run times for the modeling process. Consider trying out both and seeing what works best for your model.',
                                             'In the graphs to the right, you can explore how changing hyperparameters effect adstocking for your paid media variables. Try checking out both the Weibull adstock and Geometric adstock options to get an understanding of the difference.',
                                             sep = '<br><br>'),
                             placement = 'right', trigger = 'focus', options = list(container = 'body')
                             ),
                   uiOutput('model_window_min'),
                   uiOutput('model_window_max'),
                   textInput('hyperpar_optim_algo', label = h4('Select Hyperparameter Optimization Algorithm',
                                                              tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                                              bsButton("optimization_selection_popover", label = "", icon = icon("question"), style = "info", size = "extra-small")),
                             value = 'DiscreteOnePlusOne'),
                   bsPopover(id = 'optimization_selection_popover', title = 'Selecting a Hyperparameter Optimization Algorithm',
                             content = paste0('Robyn uses ',a('NeverGrad', href = 'https://facebookresearch.github.io/nevergrad/', target = '_blank'), ' a gradient-free optimization platform combined with an evolutionary algorithm to optimize the models. Currently, the recommended algorithm tested with Robyn is <b>TwoPointsDE</b>. Unless you have a specific reason to investigate other algorithms, it is not recommended at this time.'),
                             placement = 'right', trigger = 'focus', options = list(container = 'body')
                   ),
                   numericInput('set_iter', label = h4('Set Iterations per Trial',
                                                       tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                                       bsButton("set_iter_popover", label = "", icon = icon("question"), style = "info", size = "extra-small"))
                                ,step = 1, min = 1, value = 2000),
                   bsPopover(id = 'set_iter_popover', title = 'Setting Iteration Count per Trial for Evolutionary Algorithm', 
                             content = '2000 iterations per Trial is the recommended value. More iterations will require more computation time, so use your judgement to decide what is best. Geometric adstock + 2000 iterations + 5 trials with 6 cores takes about an hour to run, Weibull adstocks will take at least double that.',
                             placement = 'right', trigger = 'focus', options = list(container = 'body')),
                   numericInput('set_trials', label = h4('Set Total Number of Trials',
                                                 tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                                 bsButton("trial_count_popover", label = "", icon = icon("question"), style = "info", size = "extra-small"))
                                ,step = 1, min = 1, value = 10),
                   bsPopover('trial_count_popover', title = 'Setting Trial Count for Evolutionary Algorithm',
                             content = 'Recommend trial count is 100 with calibration, since it will be minimizing three objective functions (NRMSE, DECOMP.RSSD, MAPE.LIFT) and 40 trials without calibration since it is only minimizing two objective functions (NRMSE, DECOMP.RSSD). <b>Robyn will create Trials * Iterations models</b>, so the more trials and the more iterations you add, the more models Robyn will build and the longer it will take to finish computation.',
                             placement = 'right', trigger = 'focus', options = list(container = 'body')),
                   textInput('dest_folder', label = 'Folder where explanatory model plots will output', value = script_path),
                   hr(style = "border-top: 1px solid #000000;"),
                   checkboxInput('enable_calibration', label = h4('Enable Model Calibration with Experiments',
                                                                tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                                                bsButton("calibration_popover", label = "", icon = icon("question"), style = "info", size = "extra-small")),
                                 value = FALSE),
                   bsPopover(id = 'calibration_popover', title = 'Model Calibration with Experiments',
                             content = paste('By applying results from randomized controlled-experiments, you may improve the accuracy of your marketing mix models dramatically. It is recommended to run these on a recurrent basis to keep the model calibrated permanently. In general, we want to compare the experiment result with the MMM estimation of a marketing channel. Conceptually, this method is like a Bayesian method, in which we use experiment results as a prior to shrink the coefficients of media variables. A good example of these types of experiments is Facebook’s conversion lift tool which can help guide the model towards a specific range of incremental values.',
                                             HTML('<img src="https://facebookexperimental.github.io/Robyn/img/calibration1.png" alt="Lamp" width = 1000 height = 400>'),
                                             'The figure illustrates the calibration process for one MMM candidate model. Facebook’s Nevergrad gradient-free optimization platform allows us to include the <b>MAPE.LIFT</b> as a third optimization score besides <b>Normalized Root Mean Square Error (NRMSE)</b> and <b>decomp.RSSD ratio</b> (Please refer to the automated hyperparameter selection and optimization for further details) providing a set of <b>Pareto optimal model solutions</b> that minimize and converge to a set of Pareto optimal model candidates.',
                                             'The reason why calibration requires more trials is as calibration with experiments is considered ground-truth, Robyn gives MAPE.LIFT "higher weight" by restricting the population of pareto optimality to the best 10% of MAPE.LIFT. Therefore, calibration requires a larger population and more trials to calculate pareto-optimal results.',
                                             'This calibration method can be applied to other media channels which run experiments, the more channels that are calibrated, the more accurate the MMM model.',
                                            '<b>In Robyn, calibration works by uploading a data file with the columns channel, liftStartDate, liftEndDate, liftAbs</b>. channel - Name of the paid media channel the test ran on, liftStartDate - the day the test began, liftEndDate - the day the test ended, liftAbs - the incremental revenue/conversions (whichever is your dependent variable)',
                                            '<b>Ensure that any calibration data you include matches exactly what you have input as that channel data. For example, if a lift study only covered a portion of your Facebook media, you should not use it to calibrate your entire Facebook media variable.',
                                            sep = '<br><br>'),
                             placement = 'right', trigger = 'focus', options = list(container = 'body')
                   ),
                   uiOutput('calibration_file'),
                   uiOutput('calib_file_date_format'),
                   
                   hr(style = "border-top: 1px solid #000000;"),
                   numericInput('cores_used', label = h4('Cores Used for Parallel Computation',
                                                         tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                                         bsButton("cores_popover", label = "", icon = icon("question"), style = "info", size = "extra-small"))
                                ,step = 1, min = 1, value = 2),
                   bsPopover(id = 'cores_popover', title = 'Enter the Amount of Cores to use for Parallel Computation',
                             content = 'Click the Detect Cores in CPU button to identify how many cores your machine has in the CPU. The recommendation would be to leave at least 1 core unused. Enter the amount of cores you want to use here.',
                             placement = 'right', trigger = 'focus', options = list(container = 'body')),
                   splitLayout(
                     actionButton('detect_cores', label = 'Detect Cores in CPU'), 
                     br(),
                     verbatimTextOutput('core_count')
                   ),
                   
                   hr(style = "border-top: 1px solid #000000;"),
                   checkboxInput('prophet_enable_checkbox', label = h4('Enable Prophet',
                                                                       tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                                                       bsButton("prophet_popover", label = "", icon = icon("question"), style = "info", size = "extra-small"))
                                 , value = TRUE),
                   bsPopover(id = 'prophet_popover', title = 'Using Prophet to Account for Time-based Trends', 
                             content = paste(paste0('Prophet has been included in the code in order to improve fit and forecast time series by decomposing the data into trend, seasonality, holiday and weekday (if you are using daily data) components. Prophet is a Facebook original procedure for forecasting time series data based on a model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday and weekday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. ',a('More details can be found here', href = 'https://facebook.github.io/prophet/', target = '_blank')),
                                             'If you do not already have trend/seasonality data of your own, we would recommend you consider using Prophet for at least trend & season, but as the complexity of the model and industry being measured increases, it may be worthwhile exploring additional ways to account for time-based trends. Additionally, it could potentially help the fit of the model if you believe holidays or day of the week have an impact on your dependent variable to include those as well.',
                                             sep = '<br><br>'),
                             placement = 'right', trigger = 'focus', options = list(container = 'body')),
                   splitLayout(
                     uiOutput('prophet_country'),
                     uiOutput('prophet_enable'),
                     uiOutput('prophet_signs')
                   )
                 ),
                 mainPanel(width = 7,
                   splitLayout(cellWidths = c('40%','20%','20%'),
                    bsButton("finalize_inputs_popover", label = 'Info on Finalizing your Inputs - The Last Step before Modeling', style = "info", size = "small"),
                    bsPopover(id = 'finalize_inputs_popover', title = 'Finalizing your Inputs - The Last Step before Modeling',
                              content = paste('Clicking the Finalizing All Model Inputs button will finalize all of your inputs from this tab and the previous tabs. You can always go back and change something and click this button again to update values. If there is an error here you will need to go back and fix an input somewhere.',
                              'If everything looks good you will get a message that says so and then you can move on to <b>Initiate ROBYN Modeling</b> and click there! As the model runs, you will be able to see output about the progress updating on the bottom of the page below the hyperparameter sliders and calibration data table.',
                              sep = '<br><br>'),
                              placement = 'right', trigger = 'focus', options = list(container = 'body')),
                    actionButton('finalize_hyperparams', label = 'Finalize All Model Inputs'), 
                    actionButton('run_model', label = 'Initiate ROBYN Modelling')
                   ),
                   textOutput('model_gen_text'),
                   hr(style = "border-top: 1px solid #000000;"),
                   bsButton("response_curve_popover", label = "Understanding Cost-Response & Adstock Curves", style = "info", size = "small"),
                   bsPopover('response_curve_popover', title = 'Understanding your Cost-Response Curves',
                             content = paste('Cost-Response curves, Response Curves, or Diminishing Returns Curves are one of the key outputs of Marketing Mix Models. The concept is that each additional unit of advertising increases the response, but at a diminishing rate. With these curves, Marketers can understand at what their optimal investment level in a given channel is, or when used in aggregate, how to make overall budget investment decisions.',
                                             'A key principle that these Response curves follow is the theory of diminishing returns. This means that at a certain point we expect the return on investment of ($X+1 - $X) < ($X - $X-1) or in other words, the profitability of any given channel will eventually reach a point where it is no longer an acceptable return on investment for a business. Typically, when ROI < 1.',
                                             'These Response Curves also have hyperparameters - Alpha and Gamma. These hyperparameters will effect the shape of the response curve. The higher the <b>Alpha</b> hyperparameter, the more S-shape the curve will be. The lower the Alpha, the more C-shape the hyperparameter will be. For <b>Gamma</b> hyperparameters, the higher the value the higher the inflection point will be, or in other words, the higher the level of investment that the channel will start hitting diminishing returns on investment. The inflection point is also the point at which marginal ROI is at its maximum. A lower Gamma means that the channel will reach a saturation point at a lower level of investment.',
                                             'Please look at the charts here to get a better understanding of how these response curves may behave. Shortly you will have response curves of your own generated!',
                                             sep = '<br><br>'
                             )),
                   splitLayout(
                     plotOutput('adstock_curves_samples'),
                     plotOutput('response_curves_samples')
                     )
                   ,
                   hr(style = "border-top: 1px solid #000000;"),
                   bsButton('hyperparam_slider_popover', label = 'Explanation of Default Ranges for Hyperparameters', style = 'info', size = 'small'),
                   br(),
                   br(),
                   bsPopover('hyperparam_slider_popover', title = 'Default Ranges for Hyperparameters', 
                             content = paste('We have set the default hyperparameter ranges for each channel to be fairly wide so that the evolutionary algorithm has ample room to move when testing different combinations of values. For some more guidance from the Robyn team - ',
                                             'For geometric adstock, use theta, alpha & gamma. For weibull adstock, use shape, scale, alpha, gamma',
                                             '<b>Theta</b>: In geometric adstock, theta is decay rate. guideline for usual media genre: TV c(0.3, 0.8), OOH/Print/Radio c(0.1, 0.4), digital c(0, 0.3). Please note that the recommended theta values are for weekly data. Increase range to higher values for daily data. For an example of TV, 80% theta means half-life of 4 periods. In other words, for weekly data, the effect of the TV reduces to half after 4 weeks. For daily data, half-life of 80% decay will be 4 days. Adapt theta to match expectation.' ,
                                             '<b>Shape</b>: In weibull adstock, shape controls the decay shape. Recommended c(0.0001, 2). The larger, the more S-shape thus the stronger the carry-over effect. The smaller, the more L-shape thus the weaker the carry-over effect.',
                                             '<b>Scale</b>: In weibull adstock, scale controls the decay inflexion point. Very conservative recommended bounce c(0, 0.1), becausee scale can increase adstocking half-life greatly',
                                             '<b>Alpha</b>: In s-curve transformation with hill function, alpha controls the shape between exponential and s-shape. Recommended c(0.5, 3). The larger the alpha, the more S-shape. The smaller, the more C-shape',
                                             '<b>Gamma</b>: In s-curve transformation with hill function, gamma controls the inflexion point. Recommended bounce c(0.3, 1). The larger the gamma, the later the inflection point in the response curve or in other words, the later the maximum point of marginal ROI will be.',
                                             'This is not meant to be set in stone or a hard recommendation. If a prior analysis points you in a different direction feel free to pursue that',
                                             sep = '<br><br>'
                                             ),
                             placement = 'right', trigger = 'focus', options = list(container = 'body')
                             )
                   ,
                   uiOutput('local_hyperparam_sliders_paid'),
                   uiOutput('local_hyperparam_sliders_organic'),
                   hr(style = "border-top: 1px solid #000000;"),
                   dataTableOutput('lift_calib_tbl', width = '1000')
                 )
               )
      ),
      tabPanel((title='Model Selection'),
        sidebarLayout(
          sidebarPanel(
                       bsButton('pareto_front_popover', label = 'Interpreting your pareto-optimal solutions', style = 'info', size = 'small'),
                       bsPopover(id = 'pareto_front_popover', title = 'Making sense of your model solutions',
                                 content = paste(paste0('In Robyn, essentially what we are trying to do is create a large quantity of a large quantity of gradient-free ',a('evolutionary-optimization algorithm',href = 'https://facebookresearch.github.io/nevergrad/', target = '_blank'), ' model solutions for ',a('pareto-optimal',href = 'https://en.wikipedia.org/wiki/Pareto_efficiency', target = '_blank'),' model selection using three objective functions (or two in the case you are not calibrating your results with experimental data). '),
                                 'The first of these is <b>NRMSE or Normalized Root Mean Square Error</b>. NRMSE is equivalent to the RMSE / mean(observed). In other words, it is a measure of how much error there is between the observed values vs. what the model predicts the value to be. Naturally a high error is worse than a low error, and the closer to 0 the better.',
                                 'The second of these is <b>Decomp.RSSD or Decomposition Root Sum of Squared Distance</b>. This metric in essence is measuring the distance between the share of the media spend, and the share of effect per the model for the paid media variables. In this sense, Decomp.RSSD is more a measure of quality of the model/business logic since we would expect to disregard models where the results were extremely different than the levels of spend we currently use on certain channels. For example, if the share of spend for a channel was 10% but the share of effect was 90%, that would be concerning and a result marketers would likely not believe.',
                                 'The third of these is <b>MAPE.lift or the Mean Absolute Percent Error vs. your experimental Calibration data</b>. Calibrating your model with experimental data is an important way to ensure believability of the model and alignment with ground-truth. As such, minimizing the error against this data for the model helps us select solutions that align with that ground-truth best.',
                                 'In the chart below, you will see a large number of points and a few lines. Each one of these points is an evolutionary algorithm optimised solution, and each solution that occurs on one of the three lines or Pareto-Fronts is a Pareto-Optimal solution. Since we are minimizing 2 or 3 loss functions it can be difficult to make the conclusion that a difference in any one of the loss functions is more important than the others, so best practices would be to dig into a number of the models along the pareto fronts to identify which suits your business best.',
                                 'We will talk more about how to choose a model that makes sense, and provide some proactive guidance after you select a model solID to investigate. A number of explanatory charts will appear, that will help us identify models that make the most sense.'
                                  ,sep = '<br><br>'),
                                 placement = 'right', trigger = 'focus', options = list(container = 'body')),
                       br(),
                       br(),
                       plotOutput("pParFront", click = "plot_click"),
                       tableOutput('model_selection_info'),
                       br(),
                       br(),
                       uiOutput('plots_folder'),
                       #textInput('folder', label = div("Directory containing plots"), value = paste0(script_path,plot_folder_sub)),
                       textInput('plot', label = div("solID"), value = ""),
                       actionButton('load_charts', label = 'Load Charts'),
                       br(),
                       br(),
                       actionButton('save_model', label = 'IMPORTANT! CLICK HERE SAVE CURRENT solID', class = 'btn-warning'),
                       width = 4),
          mainPanel(
            dataTableOutput('pareto_front_tbl', width = '1000'),
            br(),
            br(),
            uiOutput('model_output_expl_gen'),
            br(),
            br(),
            uiOutput('model_output_expl_1'),
            br(),
            br(),
            uiOutput('model_output_expl_2'),
            br(),
            br(),
            uiOutput('model_output_expl_3'),
            br(),
            br(),
            dataTableOutput('model_summary_tbl', width = '1000'),
            br(),
            br(),
            uiOutput('load_selection_plot')
            )
          )
        ),
      tabPanel((title = 'Budget Optimization - Scenario Planner'),
        sidebarLayout(
          sidebarPanel(actionButton('run_opt',label = 'Run Optimizer'),
                       hr(),
                        textInput('solID',label= h4('Model solID',
                                                             tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                                             bsButton("opt_solid_pop",label = '', icon = icon("question"), style = "info", size = "extra-small")), value = NULL),
                       bsPopover(id = 'opt_solid_pop', title = 'Input your selected model\'s solID',
                                 content = paste0('In the previous model selection tab, you should have found a model solution solID that you are interested in tracking.'),
                                 placement = 'right', trigger = 'focus', options = list(container = 'body')),
                       selectInput('opt_scenario',label = h4('Optimization Scenario',
                                                             tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                                             bsButton("opt_scen_pop", label = '',icon = icon("question"), style = "info", size = "extra-small"))
                                   ,choices = list('max_historical_response', 'max_response_expected_spend'), selectize = F),
                       bsPopover(id = 'opt_scen_pop', title = 'Choose the Optimization Scenario',
                                 content='There are two options for the optimization scenario. <b>Max historical response</b>, which uses the same spend and amount of time as the historical periods, and <b>Max response expected spend</b>, where you can input a number of days and spend value for scenario planning.',
                                 placement = 'right', trigger = 'focus', options = list(container = 'body')),
                       uiOutput('expected_spend'),
                       uiOutput('expected_days'),
                       br(),
                       br(),
                       bsButton('opt_sliders', label = 'Setting optimization boundaries', style = 'info'),
                       bsPopover(id = 'opt_sliders', title = 'Setting and Understanding your Optimization Boundaries',
                                 content = 'As we think about reallocating budgets, it is important to set some boundaries so that we are not producing results that would be unreasonable to present to the team making budgetary decisions. Oftentimes, this is put in place as a proportion up or down by which you are willing to adjust an individual channels spend by in order to optimize. For each of the sliders below, lets say we set the boundaries to be 0.8 to 1.2. This would mean that we would be comfortable changing the mean spend per period of this channel to be anywhere between 80% or 120% times the mean spend during the historical period. As you think about what makes sense for your business, consider discussing with the marketing team what boundaries they would like to put in place here.',
                                 placement = 'right', trigger = 'focus', options = list(container = 'body')),
                       br(),
                       br(),
                       uiOutput('sliders')
                       ),
          mainPanel(
            withSpinner(plotOutput('optimizer_plot',height = 800)),
            withSpinner(dataTableOutput('optimizer_tbl', width= '1000'))
            )
          )
        )
      
      )
#       ,
#       navbarMenu(title = 'Refresh or work with Existing Model',
#                  tabPanel(title = 'Refresh Model',
#                     sidebarLayout(
#                       sidebarPanel(
#                         bsButton('existingModel',label = 'Refreshing your Existing Model', style = 'info'),
#                         bsPopover(id = 'existingModel', title = 'Refreshing your previously built MMM',
#                                   content = '',
#                                   placement = 'right', trigger = 'focus', options = list(container = 'body')),
#                         textInput('existing_model_path', label = '' ,value = ''),
#                         fileInput('data_file_e', label = h4('Choose CSV File containing data, with column names in first row ',
#                                                           tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
#                                                           bsButton("data_file_popover_e", label = "", icon = icon("question"), style = "info", size = "extra-small")),
#                                   accept = '.csv'),
#                         bsPopover(id = 'data_file_popover_e', title = 'Choosing a CSV File for your main dataset',
#                                   content = paste0('Upload your dataset here. The file must be of .csv type, and should contain at least a column for a date variable, '
#                                                    ,'and an independent variable such as revenue or conversions. For an example of what this file could look like, see the de_simulated_data.csv '
#                                                    ,'file in the ', 
#                                                    a('github repository. ', href = 'https://github.com/facebookexperimental/Robyn/blob/master/source/de_simulated_data.csv', target = '_blank'),
#                                                    'Additionally, for more detailed information on this step please refer to the ',
#                                                    a('step by step guide.', href = 'https://facebookexperimental.github.io/Robyn/docs/step-by-step-guide#load-data', target = '_blank')
#                                   ),
#                                   placement = 'right', trigger = 'focus', option = list(container = 'body')),
#                         fileInput('holiday_file_e', label = h4('Choose CSV File containing holiday info',
#                                                              tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
#                                                              bsButton("holiday_file_popover_e", label = "", icon = icon("question"), style = "info", size = "extra-small")),
#                                   accept = '.csv'),
#                         bsPopover(id = 'holiday_file_popover_e', title = 'Choose a file that contains holiday data for your region of choice',
#                                   content = paste0('Upload your dataset containing holiday data. If you do not have a separate file',
#                                                    ', in the github repository there is a file called holidays.csv that you can access ',
#                                                    'here containing holiday data going back and forward many years. Click ',
#                                                    a('here.', href = 'https://github.com/facebookexperimental/Robyn/blob/master/source/holidays.csv'),
#                                                    ' If you do have your own holiday file, ensure the formatting is the same as this file.'),
#                                   placement = 'right', trigger = 'focus', option = list(container = 'body')),
#                         numericInput('refresh_steps',value = 1, min = 1, max = NA, step = 1,label = ''),
#                         selectInput('refresh_mode', choices = c('auto','manual'), selected = 'auto', label = ''),
#                         numericInput('refresh_iters',value = 1000, min = 1, max = NA, step = 1 , label = ''),
#                         numericInput('refresh_trials',value = 3, min = 1, max = NA, step = 1, label = ''),
#                         actionButton('refresh_run', label = 'Run Model Refresh')
#                       ),
#                       mainPanel(
#                         
#                       )
# 
#                           )),
#                  tabPanel(title = 'Budget Optimization - Scenario Planner')
#       ),
#       tabPanel(title = 'Response Curve Sandbox',
# )
                 
    )
  )

################################### Server #######################################


server <- function(input, output, session){
  session$onSessionEnded(function() {
    stopApp()
  })
  #need to remove this if ever hosted non-locally since can lead to injection attacks, it allows table tags to be used in popovers
  runjs('$.fn.popover.Constructor.DEFAULTS.sanitize = false')
  #robyn_object <- "~/Desktop/Robyn.RData"
  if(rstudioapi::isAvailable()){
    Sys.setenv(R_FUTURE_FORK_ENABLE="true")
    options(future.fork.enable = TRUE)
    }
  ################################### Data Input tab server functionality #######################################
  
  output$data_tbl <- renderDataTable({
    file <- input$data_file
    ext <- tools::file_ext(file$datapath)
    validate(need(ext == 'csv', 'Please upload a csv file'))
    mmm_data <<- fread(file$datapath) #save dt_input as global var within server function
    #mmm_data_colnames <<- colnames(mmm_data)
    datatable(head(mmm_data, n = 5L)
              , options = list(scrollX = T, scrollCollapse = T, lengthChange = F, sDom = 't'))
  })
  
  colnames_reactive <- reactive({
    if(!is.null(input$data_file)){
      file <- input$data_file
      ext <- tools::file_ext(file$datapath)
      validate(need(ext == 'csv', 'Please upload a csv file'))
      my_data <- fread(file$datapath)
    }
  })
  observe({
    updateSelectInput(session, 'dep_var', choices = names(colnames_reactive()))
    updateSelectInput(session, 'date_var', choices = names(colnames_reactive()))
  })
  
  output$hol_tbl<- renderDataTable({
    hol_file <- input$holiday_file
    hol_ext <- tools::file_ext(hol_file$datapath)
    validate(need(hol_ext=='csv','Please upload a csv file'))
    holiday_data <<- fread(hol_file$datapath)
    datatable(head(holiday_data,n=5L), options = list(scrollX = T, scrollCollapse = T, lengthChange = F, sDom = 't'))
  })
  
  observeEvent(input$init_var_input, {
    
    output$var_assignment_descipt <- renderUI({
      splitLayout(cellWidths = c('100%','0%'),
      bsButton('var_assignment_button', label = 'Reminder on Variable Assignment', size = 'small'),
      bsPopover(id = 'var_assignment_button',title = 'Variable Assignment Tip', content = 'Remember, if you do not have a impression/click variable for a given media channel input the spend variable associated with that channel into <b>BOTH</b> fields for that channel.',
                placement = 'bottom',trigger = 'focus',options = list(container = 'body')))
    })
    output$media_vars <- renderUI({
      if(isolate(input$num_media) >= 1){
      lapply(1:isolate(input$num_media), function(i){
        fluidRow(column(width = 8,
        splitLayout(
          selectInput(paste0('media_var_impr_',toString(i)),label=paste0('Paid Media Variable Action (Imp/Click) Column #',toString(i)),choices = colnames(mmm_data),selectize = F),
          selectInput(paste0('media_var_spend_',toString(i)),label=,paste0('Paid Media Spend Column #',toString(i)),choices = colnames(mmm_data),selectize = F)
        ),
        br(),
        br()
        ))
      })
      }
    })
    
    output$org_media_vars <- renderUI({
      if(isolate(input$num_organic_media) >= 1){
        lapply(1:isolate(input$num_organic_media), function(j){
          fluidRow(column(width = 8,
                            selectInput(paste0('org_media_var_impr_',toString(j)),label=paste0('Organic Media Variable Action (Imp/Click) Column #',toString(j)),choices = colnames(mmm_data),selectize = F),
                          br(),
                          br()
          ))
        })
      }
    })
    
    output$context_vars <- renderUI({
      if(isolate(input$num_context) >= 1){
      lapply(1:isolate(input$num_context), function(k){
        splitLayout(
          selectInput(paste0('baseline_var_name_',toString(k)),label = paste0('Column Name for Contextual Variable #',toString(k)),choices = colnames(mmm_data),selectize = F),
          radioButtons(paste0('baseline_var_name_sign_',toString(k)), label = div(paste0('Force positive/negative sign for Contextual Variable #',toString(k)),style = "font-size:12px;"), choices = c('default','positive','negative'), inline = T),
          checkboxInput(paste0('baseline_var_name_checkbox_',toString(k)),label = div(paste0('Check If Contextual Variable #',toString(k),' is a factor/categorical/indicator.'),style = "font-size:12px;"), value = F)
        )
      })
      }
    })
    
    output$finalize_vars <- renderUI({
      actionButton('finalize_var_input',label = h4('Finalize Variable Assignment',
                                          tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                            bsButton("fin_var_assign_popover", label = "", icon = icon("question"), style = "info", size = "extra-small")))
      
    })
    
    output$fin_var_assign_popover_output <- renderUI({
      bsPopover(id = 'fin_var_assign_popover', title = 'Finalizing Variable Assignment',
                content = paste('When you are confident that you have all of your variables and data input and set up correctly, click here to finalize that. ',
                                'If there is a mistake, the tool will show an error message and you will need to ensure that all column fields input into boxes are spelled correctly and contained in the data set, and all selections in the left panel are completed.',
                                sep = '<br>'),
                placement = 'right', trigger = 'focus', options = list(container = 'body'))
    })
  })
  
  observeEvent(input$finalize_var_input, {
    paid_media_vars <<- c()
    paid_media_signs <<- c()
    paid_media_spends <<- c()
    organic_vars <<- c()
    organic_signs <<- c()
    context_vars <<- c()
    context_signs <<- c()
    baseline_var_names_factor_bool_list <<- c()
    factor_vars <<- c()

      if(isolate(input$num_media) >= 1){
        lapply(1:isolate(input$num_media), function(m){
          if(isolate(input[[paste0('media_var_impr_',toString(m))]]) != ''){
            paid_media_vars <<- c(paid_media_vars, isolate(input[[paste0('media_var_impr_',toString(m))]]))
            paid_media_signs <<- c(paid_media_signs, 'positive') #need to fix
          }
          if(isolate(input[[paste0('media_var_spend_',toString(m))]]) != ''){
            paid_media_spends <<- c(paid_media_spends, isolate(input[[paste0('media_var_spend_',toString(m))]]))
          }
        }
        )}
      if(isolate(input$num_context) >= 1){
        lapply(1:isolate(input$num_context), function(r){
          context_vars <<- c(context_vars, isolate(input[[paste0('baseline_var_name_',toString(r))]]))
          context_signs <<- c(context_signs, isolate(input[[paste0('baseline_var_name_sign_',toString(r))]]))
        })
        lapply(1:isolate(input$num_context), function(r){
          baseline_var_names_factor_bool_list <<- c(baseline_var_names_factor_bool_list, isolate(input[[paste0('baseline_var_name_checkbox_', toString(r))]]))
        })
        factor_vars <<- context_vars[which(baseline_var_names_factor_bool_list == T)]
      }
      if(isolate(input$num_organic_media) >= 1){
        lapply(1:isolate(input$num_organic_media), function(x){
        if(isolate(input[[paste0('org_media_var_impr_',toString(x))]]) != ''){
          organic_vars <<- c(organic_vars, isolate(input[[paste0('org_media_var_impr_',toString(x))]]))
          organic_signs <<- c(organic_signs, 'positive') #need to fix
        }
        }
        )}
      
      med_vars_impr_in_cols <- ifelse(length(intersect(paid_media_vars,colnames(mmm_data))) == 
                                   length(unique(paid_media_vars)),T,F)
      med_vars_spend_in_cols <- ifelse(length(intersect(paid_media_spends,colnames(mmm_data))) == 
                                   length(unique(paid_media_spends)),T,F)
      org_med_vars_in_cols <- ifelse(length(intersect(organic_vars,colnames(mmm_data))) ==
                                       length(unique(organic_vars)),T,F)
      baseline_vars_in_cols <- ifelse(length(intersect(context_vars,as.list(colnames(mmm_data)))) ==  
                                   length(unique(context_vars)),T,F)
      
      date_transf_data<-tryCatch({a<-(isolate(mmm_data) %>% mutate(isolate(input$date_var) ,as.Date(isolate(input$date_var), format = isolate(input$date_format_var))) %>% summarize(sum(is.na(input$date_var))))},
          warning = function(w){return('')},
          error = function(e){return('')},
        finally = function(f){return(a[1,])}
         )
      
  #output$vars_finalized <- renderText({
      
      if((is.null(isolate(input$data_file)) == F) & 
         (is.null(isolate(input$holiday_file)) == F) & 
         ((isolate(input$dep_var) == '') == F) & 
         ((isolate(input$date_var) == '') == F) & 
         ((isolate(input$date_format_var) == '')==F) &
         (date_transf_data == 0) &
         ((isolate(length(intersect(input$dep_var,as.list(colnames(mmm_data))))==1))==T) &
         ((isolate(length(intersect(input$date_var,as.list(colnames(mmm_data))))==1))==T) &
         (is.null(isolate(input$num_media)) == F) & 
         (is.null(isolate(input$num_organic_media)) == F) & 
         (is.null(isolate(input$num_context)) == F) &
         (length(paid_media_vars) == isolate(input$num_media))&
         (length(paid_media_spends) == isolate(input$num_media)) & 
         (length(organic_vars) == isolate(input$num_organic_media))&
         (length(context_vars) == isolate(input$num_context)) &
         (mmm_data %>% select(c(paid_media_vars,organic_vars,isolate(input$dep_var))) %>% sapply(is.numeric) %>% all() == T) & #force numeric paid media vars and dep var
         (med_vars_impr_in_cols == T) &
         (med_vars_spend_in_cols == T) & 
         (org_med_vars_in_cols == T) &
         (baseline_vars_in_cols == T)){
            dt_input <<- isolate(mmm_data)
            #fix formatting of Date variable
            # dt_input %>% mutate(isolate(input$date_var) ,as.Date(isolate(input$date_var), format = isolate(input$date_format_var)))
            
            dt_input <<- dt_input[,DATE:=as.Date(get(isolate(input$date_var)), isolate(input$date_format_var))]
            dt_input$DATE <<- as.Date(gsub('00','20',dt_input$DATE))
            dt_holidays <<- isolate(holiday_data)
            dep_var <<- isolate(input$dep_var)
            dep_var_type <<- isolate(input$dep_var_type)
            #set_depVarType <<- isolate(input$dep_var_type)
            date_var <<- 'DATE'
            showModal(modalDialog(
              title = "Variable Input Succesful - Please click anywhere on the screen to proceed.",
              easyClose = TRUE,
              footer = NULL
            ))
            'Input Succesful - Please click anywhere on the screen to proceed.'
         }else {
           error_message <- NULL
           if(is.null(isolate(input$data_file)) == T){error_message <- paste(error_message,'Issue with Data File',sep = '<br><br>')}
           if(is.null(isolate(input$holiday_file)) == T){error_message <- paste(error_message,'Issue with Holiday File',sep = '<br><br>')}
           if(((isolate(input$dep_var) == '') == T) | isolate(length(intersect(input$dep_var,as.list(colnames(mmm_data))))!=1)){error_message <- paste(error_message,'Issue with Dependent Variable Name - Either none input, or input case-sensitive column name does not exist in data file',sep = '<br><br>')}
           if(((isolate(input$date_var) == '') == T) |  isolate(length(intersect(input$date_var,as.list(colnames(mmm_data))))!=1)){error_message <- paste(error_message,'Issue with Date Var Name, either none input or input case-sensitive column name does not exist in data file',sep = '<br><br>')}
           if(((isolate(input$date_format_var) == '') == T) |  (date_transf_data > 0)){error_message <- paste(error_message,'Issue with Date Format Var, either none input or input format does not work for all rows. I.e. 1+ rows are transformed to NA',sep = '<br><br>')}
           if(is.null(isolate(input$num_media)) == T){error_message <- paste(error_message,'No number input for number of media variables',sep = '<br>')}
           if(is.null(isolate(input$num_context)) == T){error_message <- paste(error_message,'No number input for number of baseline variables',sep = '<br>')}
           if(length(paid_media_vars) != isolate(input$num_media)){error_message <- paste(error_message,'Missing Input for >=1 media impression/click variable column names. If you do not have a media impression/click variable for a given channel enter its spend variable into the impression/click field for that variable, so you will have that spend variable input both times.',sep = '<br><br>')}
           if(length(paid_media_spends) != isolate(input$num_media)){error_message <- paste(error_message,'Missing Input for >=1 media spend variable column names',sep = '<br><br>')}
           if(length(context_vars) != isolate(input$num_context)){error_message <- paste(error_message,'Missing Input for >=1 baseline variable column names',sep = '<br><br>')}
           if(med_vars_impr_in_cols == F){error_message <- paste(error_message,'At least 1 column name in the input media impression/click variable column names does not match the column names in the data. Remember they must be input case-sensitive.',sep = '<br><br>')}
           if(med_vars_spend_in_cols == F) {error_message <- paste(error_message,'At least 1 column name in the input media spend variable column names does not match the column names in the data. Remember they must be input case-sensitive.',sep = '<br><br>')}
           if(baseline_vars_in_cols == F){error_message <- paste(error_message,'At least 1 column name in the input baseline variable column names does not match the column names in the data. Remember they must be input case-sensitive.',sep = '<br><br>')}
           if(mmm_data %>% select(paid_media_vars) %>% sapply(is.numeric) %>% all() == F){error_message <- paste(error_message,'At least 1 paid media variable column is not of the type NUMERIC - ensure that any non-numeric characters are removed from all paid media columns (e.g. "$", ",")',sep = '<br><br>')}
           if(input$num_organic_media>0){if(mmm_data %>% select(organic_media_vars) %>% sapply(is.numeric) %>% all() == F){error_message <- paste(error_message,'At least 1 Organic media variable column is not of the type NUMERIC - ensure that any non-numeric characters are removed from all paid media columns (e.g. "$", ",")',sep = '<br><br>')}}
           if(mmm_data %>% select(isolate(input$dep_var)) %>% sapply(is.numeric) %>% all() == F){error_message <- paste(error_message,'Dependent variable column is not of the type NUMERIC - ensure that any non-numeric characters are removed from the dependent variable column (e.g. "$", ",")',sep = '<br><br>')}
           if(mmm_data %>% is.na() %>% any() == T){error_message <- paste(error_message,'Dataset has <NA> or missing values. These values must be removed or fixed for the model to properly run. Please investigate row number(s) - ', paste(which(rowSums(is.na(mmm_data)) > 0),collapse = ', '),sep = '<br><br>')}
           suppressWarnings({
             rm(context_vars, envir=.GlobalEnv)
             rm(context_signs,envir=.GlobalEnv)
             rm(paid_media_vars, envir = .GlobalEnv)
             rm(paid_media_signs, envir = .GlobalEnv)
             rm(paid_media_spends, envir = .GlobalEnv)
             rm(factor_vars, envir = .GlobalEnv)
             rm(baseline_var_names_factor_bool_list, envir = .GlobalEnv)
             rm(dt_input, envir=.GlobalEnv)
             rm(organic_vars, envir=.GlobalEnv)
             rm(organic_signs, envir=.GlobalEnv)
             rm(dt_holidays, envir = .GlobalEnv)
             rm(dep_var, envir = .GlobalEnv)
             rm(set_country, envir = .GlobalEnv)
             rm(date_var, envir = .GlobalEnv)
           })
           showModal(modalDialog(
             title = HTML(paste('<b>Variable Inputs not saved due to errors -</b>',error_message,sep = '<br>')),
             easyClose = TRUE,
             footer = NULL
           ))
        }
  })
  
  ######################## Exploratory Data Analysis tab functionality ######################
  observeEvent(input$EDA_initiate,
               { vars_inputted <- unique(c(date_var,dep_var,paid_media_spends,paid_media_vars,organic_vars,context_vars))
               eda_input <<- dt_input[,..vars_inputted]
               ##############################################################
               ####   1. Examine data completeness for all variables    #####
               ##   Get percent of non-missing data for all variables   #####
               ##############################################################
               no_rows <- length(eda_input$DATE) #Get number of rows in the input data
               nonNA_counts <- eda_input[, lapply(.SD, function(x) sum(!is.na(x))), .SDcols = names(eda_input)]
               nonNA_counts_long <- nonNA_counts %>%
                 pivot_longer(cols = everything(), names_to = "variable", values_to = "non_NA_count")
               nonNA_counts_long <- as.data.table(nonNA_counts_long)
               nonNA_counts_long[,pct_of_non_missing_data:= round(non_NA_count*1.00/no_rows,2)]
               nonNA_counts_long[,pct_of_non_missing_data_cat:= ifelse(pct_of_non_missing_data==1,"Data is complete","Has missing data")]
               
               # Dynamic warning message based on pct of non-missing data:
               message_1_bad <- paste0("<B>1. Percent of Non-Missing Data for Each Variable:</B>", "<br>",
                                       "Variable ",
                                       vector.print.with.and(nonNA_counts_long[pct_of_non_missing_data_cat=="Has missing data",variable],
                                                             string_to_return_if_vector_is_empty = "(None)"),
                                       " has missing data. ",
                                       "", "The Robyn MMM model will not run properly on a dataset with missing data. Examine the variable(s) with missing data to see if the missing data can be added or imputed. 
                                         There are different techniques to impute or interpolate missing data for time series type of data, such as mean, median, linear, and spline interpolation, etc.
                                         We encourage you to do some research to see what makes the most sensse for your data. ",
                                       " ","Refer to chart 1 (Percent of non-missing data for each variable) for more detail.")
               
               message_1_good <- paste0("<B>1. Percent of Non-Missing Data for Each Variable:</B>",
                                        "<br>",
                                        "None of the variables has missing data. No action is needed here.",
                                        " ","You can still refer to chart 1 (Percent of non-missing data for each variable) for more detail.")
               
               # Decide which message to show:
               message_1 <- ifelse(sum(nonNA_counts_long$pct_of_non_missing_data_cat=="Has missing data")>=1,
                                   message_1_bad, message_1_good)
               
               output$print_message_1 <- renderText(paste0(message_1,"<br>","<br>"))
               
               
               ####################################################################
               ###        2. Examine completeness of time periods:             ####
               ##   Get number of observations by year, month, week, weekday   ####
               ##     to capture any inconsistency in the input data           ####
               ####################################################################
               
               # Prepare the data for getting the missing time periods:
               date_column <- setorder(eda_input[,c("DATE")],DATE)
               date_column[ ,date_previous_row := shift(DATE, 1L, type="lag")]
               date_column[ ,date_diff_in_days :=difftime(DATE, date_previous_row, units = c("days"))]
               
               # Calculate the correct lag
               correct_lag <- min(as.numeric(date_column$date_diff_in_days),na.rm = TRUE)
               
               # Dynamic warning message based on missing time periods:
               message_2_bad <- paste0("<B>2. Missing Time Periods:</B>", "<br>",
                                       "There seems to be some missing time period(s) after: ",
                                       vector.print.with.and(date_column[date_diff_in_days > correct_lag, date_previous_row],
                                                             string_to_return_if_vector_is_empty = "(None)"),
                                       ".",
                                       " ", "Data completeness is crucial to the quality of the model.",
                                       " ","Examine the missing time periods to see if data for those time periods can be added.",
                                       " ","Refer to charts 2a-2d (Number of observations by year, month, week and weekday) to see if the missing time periods follow certain patterns.")
               
               message_2_good <- paste0("<B>2. Missing Time Periods:</B>",
                                        "<br>",
                                        "The time periods in your data seem to be complete. No action is needed here.",
                                        " ","You can still refer to charts 2a-2d (Number of observations by year, month, week and weekday) to check the patterns of the time periods along these dimensions.")
               
               # Decide which message to show:
               message_2 <- ifelse(sum(date_column$date_diff_in_days >correct_lag, na.rm=TRUE)>=1,
                                   message_2_bad, message_2_good)
               
               output$print_message_2 <- renderText(paste0(message_2,"<br>","<br>"))
               
               #############################################################################################
               ###        3a. Examine pair-wise correlation between all independent numeric variables:  ####
               ###                     to capture any unwanted highly-correlated variables              ####
               #############################################################################################
               # Only select the mediaspend variables and numeric baseline vars for pair-wise correlation:
               dt_pw_corr <- cbind(eda_input[,..paid_media_spends],eda_input[,..context_vars],eda_input[,..organic_vars])
               dt_pw_corr_n <- dt_pw_corr[,sapply(dt_pw_corr, is.numeric),with=FALSE]
               
               corr <- round(cor(dt_pw_corr_n,use="complete.obs"), 2) # calculate correlation matrix
               
               idx <- as.data.table(which(abs(corr) >= 0.8, arr.ind = TRUE))[col>row,] # get the indices for the matrix entries with abs(correlations) >=0.8
               
               pair_name_1 <- rownames(corr)[idx[,row]]
               pair_name_2 <- colnames(corr)[idx[,col]]
               
               # Get list of highly correlated variable pairs
               high_corr_var_pairs <- function()
               { 
                 message=""
                 for (i in 1:length(pair_name_1))
                 {message=paste0(message,"(",pair_name_1[i],", ",pair_name_2[i],") ")}
                 return(message)
               }
               
               # Get dynamic message based on correlation matrix between independent variables
               message_3a_bad <- paste0("<B>3a. Correlation Between Independent Variables:</B>",
                                        "<br>","Variable pair(s) ",high_corr_var_pairs(),
                                        "have a correlation magnitude of >=0.8 with each other.",
                                        "<br>","1) Some high correlations between independent variables are expected. For example, when two media channels have a similar spending pattern, they will naturally have a higher intercorrelation. In this case, the higher intercorrelation reflects reality and it makes sense to keep both independent variables in the model.",
                                        "<br>","2) Other higher correlations between independent variables may suggest redundancy. Consider the example of including both percent of revenue spent on video creatives and percent of revenue spent on mobile-optimal creatives. In this case, one variable clearly includes the other and it might make sense to select the one with the higher correlation with the dependent variable to include in the model.",
                                        "<br>","3) When you have both media exposure data (such as impressions, clicks, GRPs, etc.) and spend data for a specific channel, the recommendation is to choose a media exposure variable over the spend variable to include in the model, especially for offline channels where spend level doesn’t always accurately reflect the media exposure level.",
                                        "<br>","Refer to chart 3a (Pair-wise correlation between independent variable) for more detail."
               )
               
               message_3a_good <- paste0("<B>3a. Correlation Between Independent Variables:</B>",
                                         "<br>","None of the independent variables has a correlation magnitude of >=0.8 with each other. No immediate action is needed here. You can still refer to some general recommendations regarding correlation between independent variables below:",
                                         "<br>","1) Some high correlations between independent variables are expected. For example, when two media channels have a similar spending pattern, they will naturally have a higher intercorrelation. In this case, the higher intercorrelation reflects reality and it makes sense to keep both independent variables in the model.",
                                         "<br>","2) Other higher correlations between independent variables may suggest redundancy. Consider the example of including both percent of revenue spent on video creatives and percent of revenue spent on mobile-optimal creatives. In this case, one variable clearly includes the other and it might make sense to select the one with the higher correlation with the dependent variable to include in the model.",
                                         "<br>","3) When you have both media exposure data (such as impressions, clicks, GRPs, etc.) and spend data for a specific channel, the recommendation is to choose a media exposure variable over the spend variable to include in the model, especially for offline channels where spend level doesn’t always accurately reflect the media exposure level.",
                                         "<br>","Refer to chart 3a (Pair-wise correlation between independent variable) for more detail."
               )
               
               # Decide which message to show:
               message_3a <- ifelse(length(which(abs(corr)>=0.8 & corr!=1))>=1,message_3a_bad,message_3a_good)
               
               output$print_message_3a <- renderText(paste0(message_3a,"<br>","<br>"))
               
               
               ###############################################################################################
               ###        3b. Examine correlation of all numeric variables against dependent variable:    ####
               ###                 to capture any unwanted highly-correlated variables                    ####
               ###############################################################################################
               # Get a data set for all numeric variables:
               eda_input_N <- eda_input[,sapply(eda_input, is.numeric),with=FALSE]
               
               # Get correlation of all numeric variables vs. dependent variable:
               corr_w_dep_var <- eda_input_N %>% 
                 correlate(use = "complete.obs") %>% 
                 focus(all_of(dep_var)) 
               corr_w_dep_var <- as.data.table(corr_w_dep_var)
               corr_w_dep_var[,flag:=ifelse(abs(get(dep_var))>=0.8,">= 0.8","< 0.8")]
               
               # Dynamic warning message based on correlation with dependent variable:
               message_3b <- paste0("<B>3b. Correlation with Dependent Variable:</B>",
                                    "<br>","Some variables such as the baseline variables naturally have a higher correlation with the dependent variable, which is expected and is no cause for concern. However, one should avoid embedding the dependent variable within the independent variable. Examine the independent variable(s) with high correlations with the dependent variable to see if they are expected or not.",
                                    " ","Refer to chart 3b (Correlation with dependent variable) for more detail.")
               
               
               output$print_message_3b <- renderText(paste0(message_3b,"<br>","<br>"))
               
               
               ##################################################################################
               ###             4. Look at Percent of Total Media Spend by Channel            ####
               ###     to see if it makes sense to combine or break out certain channels     ####
               ##################################################################################
               
               # aggregate data to yearly sales by channel:
               eda_input_media_spend_vars <-eda_input %>% select(DATE | all_of(paid_media_spends))
               yearly_media_spend <- setorder(eda_input_media_spend_vars[, lapply(.SD, sum,na.rm = TRUE), by=.(year(DATE))],year)
               yearly_media_spend[, total_media_spend:= rowSums(.SD),
                                  .SDcols = names(eda_input_media_spend_vars)[-1]]
               
               # calculate percent of total media spend for each channel
               yearly_media_spend[, paste0("pct_",names(eda_input_media_spend_vars)[-1])
                                  :=lapply(.SD, function(x) x/total_media_spend),
                                  .SDcols = names(eda_input_media_spend_vars)[-1]]
               
               # Only keep the pct_spend variables
               yearly_media_spend_pct <- yearly_media_spend %>% select(year | starts_with("pct_"))
               
               # transform data to long format
               yearly_media_spend_pct_long <- yearly_media_spend_pct %>%
                 pivot_longer(!year, names_to = "media", values_to = "pct_of_total_media_spend")
               yearly_media_spend_pct_long<- as.data.table(yearly_media_spend_pct_long)
               yearly_media_spend_pct_long[,media:=str_replace_all(media,c("pct_"=""))]
               
               
               # Prepare data for dynamic warning message based % of total media spend by channel:
               yearly_media_spend_pct_matrix <- as.matrix(yearly_media_spend_pct)
               
               idx_low_pct <- as.data.table(which(yearly_media_spend_pct_matrix < 0.05, arr.ind = TRUE)) # get the indices for the matrix entries with value < 0.05
               pair_year_low_pct <- yearly_media_spend_pct_matrix[idx_low_pct[,row],1]
               pair_channel_low_pct <- str_replace_all(colnames(yearly_media_spend_pct_matrix)[idx_low_pct[,col]], c("pct_"="","_S"=""))
               
               idx_high_pct <- as.data.table(which(yearly_media_spend_pct_matrix > 0.6 & yearly_media_spend_pct_matrix <=1, arr.ind = TRUE)) # get the indices for the matrix entries with value >= 0.6
               pair_year_high_pct <- yearly_media_spend_pct_matrix[idx_high_pct[,row],1]
               pair_channel_high_pct <- str_replace_all(colnames(yearly_media_spend_pct_matrix)[idx_high_pct[,col]], c("pct_"="","_S"=""))
               
               # Get list of channels with low or high share of total media spend:
               low_pct_pairs <- function()
               { 
                 message=""
                 if(length(pair_year_low_pct)==0) 
                   return(message)
                 else {
                   for (i in 1:length(pair_year_low_pct))
                   {message=paste0(message," (",pair_channel_low_pct[i]," in ",pair_year_low_pct[i],")")}
                   return(message)
                 }
               }
               
               high_pct_pairs <- function()
               { 
                 message=""
                 if(length(pair_year_high_pct)==0) 
                   return(message)
                 else {
                   for (i in 1:length(pair_year_high_pct))
                   {message=paste0(message," (",pair_channel_high_pct[i]," in ",pair_year_high_pct[i],")")}
                   return(message)
                 }
               }
               
               # Dynamic warning message based % of total media spend by channel:
               
               message_4 <- paste0("<B>4. Share of Total Media Spend for Each Channel:</B>",
                                   "<br>","In general, as long as there is good variation in a channel’s spend level and its correlation with the dependent variable is not low, we recommend keeping that channel as a separate independent variable in the model. There are a couple of things to consider though when a channel’s share of total spend is very low or high:",
                                   "<br>","1) When a channel’s share of spend is high, consider meaningful splits for that channel such as prospecting/retargeting split, brand/DR campaign split etc. to potentially improve the model efficiency.",
                                   "<br>","2) When a channel’s share of spend is low and correlation with the dependent variable is also low, consider potentially grouping that channel into other similar channel(s).",
                                   "<br>","3) It is always good practice to run experiments to calibrate the MMM results to set the ground-truth and avoid bias. This is especially true when the share of spend is very low or high for a channel.",
                                   "<br>","You can refer to chart 4 for share of total media spend for each channel by year.")
               
               output$print_message_4 <- renderText(paste0(message_4,"<br>","<br>"))
               
               
               ####################################################
               ####                   Plots                   #####
               ####################################################
               pal1 <- c("Has missing data" = "tomato2", "Data is complete" = "#989898") # Set legend colors
               output$ggplot1 <- renderPlot({
                 ggplot(nonNA_counts_long,
                        aes(x=reorder(variable,-pct_of_non_missing_data),
                            y=pct_of_non_missing_data,
                            fill=pct_of_non_missing_data_cat,
                            label = scales::percent(pct_of_non_missing_data))
                 ) +
                   geom_col(width=0.6)+
                   labs(title="1. Percent of non-missing data for each variable",
                        subtitle = paste0("Examine the variables with missing data"," ","(highlighted in red below)"),
                        x="Variable",
                        y="% of non-missing data",
                        caption = paste0("Total number of observations from input data: ",length(mmm_data$DATE)),
                        fill=paste0("Data Completeness")
                   ) +
                   theme_bw(base_size = 14) +
                   scale_fill_manual(values = pal1, limits = names(pal1)) +
                   scale_y_continuous(position = "right", labels = scales::percent) +
                   geom_text(hjust = 1.1, size=3.6, colour = "white") +
                   coord_flip() +
                   theme(plot.title=element_text(size=16,  hjust=0.5, color="blue",margin=margin(5,0,5,0))) +
                   theme(plot.subtitle=element_text(size=14,  hjust=0.5, face="italic", color="firebrick")) +
                   theme(axis.title.x = element_text(vjust = 1, hjust = 1)) +
                   theme(legend.title =element_text(size=12))
               },height = 600)
               
               
               # 2.a count by year data, flag if pct_diff_vs_count_max is > 5%:
               year_counts <- setorder(mmm_data[, .(count = .N), by = year(DATE)], year)
               year_counts[, paste0("count", "_max") := lapply(.SD, max), .SDcols = "count"] 
               year_counts[,pct_diff_vs_count_max:=(count_max-count)/count_max]
               year_counts[,flag:=ifelse(pct_diff_vs_count_max>=0.05,">= 5%","< 5%")]
               year_counts[,year:=as.character(year)]
               
               
               # 2a. Plot count by year:
               pal2 <- c(">= 5%" = "tomato2", "< 5%" = "#989898") # Set legend colors
               output$ggplot2a <- renderPlot({
                 ggplot(year_counts,
                        aes(x=year,
                            y=count,
                            fill=flag,
                            label = count)) +
                   geom_col(width=0.6) +
                   labs(title="2a. Number of observations by year",
                        subtitle = paste0("Examine the year(s) with unexpected fewer number of observations"),
                        x="year",
                        y="number of observations",
                        caption = paste0("Total number of observations from input data: ",length(mmm_data$DATE)),
                        fill=paste0("% difference vs.","\n","max number of","\n","observations per year")
                   ) +
                   theme_bw(base_size = 12) +
                   scale_fill_manual(values = pal2, limits = names(pal2)) +
                   geom_text(vjust = 1.5, size=4, colour = "white") +
                   theme(plot.title=element_text(size=16,  hjust=0.5, color="blue",margin=margin(5,0,5,0))) +
                   theme(plot.subtitle=element_text(size=14,  hjust=0.5, face="italic", color="firebrick")) +
                   theme(legend.title =element_text(size=12))
               })
               
               
               # 2b. count by month data -- need to decide on flag criteria if need any
               month_counts <- setorder(mmm_data[, .(count = .N), by = month(DATE)], month)
               month_counts[, paste0("count", "_max") := lapply(.SD, max), .SDcols = "count"] 
               month_counts[,pct_diff_vs_count_max:=(count_max-count)/count_max]
               month_counts[,month_abb:=month.abb[month]]
               
               # 2b. Plot count by month:
               xaxis_ticks_2b <- month.abb[seq(1,12,1)]
               
               output$ggplot2b <- renderPlot({
                 ggplot(month_counts,
                        aes(x=reorder(month_abb,month),
                            y=count,
                            #fill=count,
                            label = count)) +
                   geom_col(width=0.6, fill="#989898") +
                   labs(title="2b. Number of observations by month",
                        subtitle = paste0("Examine the month(s) with unexpected fewer number of observations"),
                        x="month",
                        y="number of observations",
                        caption = paste0("Total number of observations from input data: ",length(mmm_data$DATE))
                        #  fill=paste0("Percent of","\n","non-missing data")
                   ) +
                   theme_bw(base_size = 12) +
                   scale_x_discrete(limits=xaxis_ticks_2b) +
                   geom_text(vjust = 1.5, size=4, colour = "white") +
                   theme(plot.title=element_text(size=16,  hjust=0.5, color="blue",margin=margin(5,0,5,0))) +
                   theme(plot.subtitle=element_text(size=14,  hjust=0.5, face="italic", color="firebrick"))
               })
               
               # 2c. count by week data, flag if count is smaller than max count per week
               week_counts <- setorder(mmm_data[, .(count = .N), by = week(DATE)], week)
               week_counts[, paste0("count", "_max") := lapply(.SD, max), .SDcols = "count"]
               week_counts[,flag:=ifelse(count<count_max,"Yes","No")]
               week_counts[,week_char:=as.character(week)]
               
               # 2c. Plot count by week:
               pal3 <- c("Yes" = "tomato2", "No" = "#989898") # Set legend colors
               xaxis_ticks_2c <- as.character(seq(1,53,1))
               
               output$ggplot2c <- renderPlot({
                 ggplot(week_counts, aes(x=reorder(week_char,week),
                                         y=count,
                                         label=count,
                                         color=flag)) + 
                   geom_point(size=3
                              #color="#989898"
                   ) + 
                   geom_segment(aes(x=reorder(week_char,week), 
                                    xend=reorder(week_char,week), 
                                    y=0, 
                                    yend=count)) +
                   # color="#989898") + 
                   labs(title="2c. Number of observations by week",
                        subtitle = paste0("Examine the week(s) with unexpected fewer number of observations"),
                        x="week of year",
                        y="number of observations",
                        caption = paste0("Total number of observations from input data: ",length(mmm_data$DATE)),
                        color=paste0("Fewer than max","\n","number of observations","\n", "per week?")
                   ) + 
                   scale_x_discrete(limits=xaxis_ticks_2c) +
                   scale_color_manual(values = pal3, limits = names(pal3)) +
                   theme_bw(base_size = 12) +
                   theme(axis.text.x = element_text(angle=65, vjust=0.6)) +
                   theme(plot.title=element_text(size=16,  hjust=0.5, color="blue",margin=margin(5,0,5,0))) +
                   theme(plot.subtitle=element_text(size=14,  hjust=0.5, face="italic", color="firebrick")) +
                   theme(legend.title =element_text(size=12))
               })
               
               # 2d. count by weekday data -- need to decide on flag criteria if need any
               weekday_counts <- setorder(mmm_data[, .(count = .N), by = weekdays(DATE)], weekdays)
               weekday_counts[, paste0("count", "_max") := lapply(.SD, max), .SDcols = "count"] 
               weekday_counts[,pct_diff_vs_count_max:=(count_max-count)/count_max]
               
               # 2d. Plot count by weekday:
               output$ggplot2d <- renderPlot({
                 ggplot(weekday_counts,
                        aes(x=weekdays,
                            y=count,
                            #fill=count,
                            label = count)) +
                   geom_col(width=0.3, fill="#989898") +
                   labs(title="2d. Number of observations by weekday",
                        subtitle = paste0("Examine the weekday(s) with unexpected fewer number of observations"),
                        x="weekday",
                        y="number of observations",
                        caption = paste0("Total number of observations from input data: ",length(mmm_data$DATE))
                   ) +
                   theme_bw(base_size = 12) +
                   geom_text(vjust = 1.5, size=4, colour = "white") +
                   theme(plot.title=element_text(size=16,  hjust=0.5, color="blue",margin=margin(5,0,5,0))) +
                   theme(plot.subtitle=element_text(size=14,  hjust=0.5, face="italic", color="firebrick"))
               })
               
               # Plot 3a
               output$ggplot3a <- renderPlot({
                 ggcorrplot(corr, hc.order = TRUE, 
                            type = "lower", 
                            lab = TRUE, 
                            lab_size = 5,
                            method="circle", 
                            colors = c("tomato2", "white", "springgreen3"), 
                            title = "3a. Pair-wise correlation between independent variables",
                            legend.title = "correlation",
                            ggtheme=theme_bw) +
                   #labs(subtitle = paste(strwrap("Examine the red circles to see if the high correlation is expected",40), collapse = "\n")) +
                   theme(plot.title=element_text(size=16, hjust=0.5, colour="blue")) +
                   theme(plot.subtitle=element_text(size=14, hjust=0.5, face="italic", color="firebrick"))
               }, height=600)
               
               # Plot 3b
               #pal4 <- c(">= 0.8" = "tomato2", "< 0.8" = "#989898") # Set legend colors
               output$ggplot3b <- renderPlot({
                 ggplot(corr_w_dep_var, aes(x = reorder(term, desc(get(dep_var))),
                                            y = get(dep_var),
                                            #fill = flag,
                                            label=round(get(dep_var),2)
                 )
                 ) +
                   geom_col(width=0.6, fill="#989898") +
                   #scale_fill_manual(values = pal4, limits = names(pal4)) +
                   labs(title="3b. Correlation with dependent variable",
                        subtitle = paste0("Examine the variable(s) with high correlations with the dependent variable to see if they are expected or not"),
                        x="variable",
                        y=paste("correlation with",dep_var)
                   ) +
                   theme_bw(base_size=14) +
                   geom_text(vjust=-0.5, size=4, colour = "black", fontface="bold") +
                   theme(plot.title=element_text(size=16, hjust=0.5, colour="blue")) +
                   theme(plot.subtitle=element_text(size=14, hjust=0.5, face="italic", color="firebrick")) +
                   theme(legend.title =element_text(size=12))
               }, height=600)
               
               # Plot 4
               # This plot will be different depending on how many years there are in the input data because stacked area chart doesn't work for single year data
               output$ggplot4 <- renderPlot({
                 ggplot4_multiple_year <- ggplot(yearly_media_spend_pct_long,
                                                 aes(x=year, y=pct_of_total_media_spend,
                                                     fill=media,
                                                     label=scales::percent(pct_of_total_media_spend,accuracy = 1L)
                                                 )
                 ) + 
                   geom_area(alpha=0.6 , size=.5, colour="white") +
                   labs(title="4. Share of total media spend for each channel",
                        x="year",
                        y="% of total media spend",
                        fill=paste("channel")
                   ) +
                   theme_bw(base_size = 12) +
                   geom_text(size = 4, position = position_stack(vjust = 0.5),fontface="bold") +
                   scale_fill_viridis(discrete = T) +
                   scale_y_continuous(labels = scales::percent) +
                   theme(plot.title=element_text(size=16,  hjust=0.5, color="blue",margin=margin(5,0,5,0))) +
                   #theme(plot.subtitle=element_text(size=14,  hjust=0.5, face="italic", color="firebrick")) +
                   theme(legend.title =element_text(size=12))
                 
                 ggplot4_single_year <- ggplot(yearly_media_spend_pct_long,
                                               aes(x=as.character(year), y=pct_of_total_media_spend,
                                                   fill=media,
                                                   label=scales::percent(pct_of_total_media_spend,accuracy = 1L)
                                               )
                 )+ 
                   geom_bar(position="stack", stat="identity") +
                   labs(title="4. Share of total media spend for each channel",
                        x="year",
                        y="% of total media spend",
                        fill=paste("channel")
                   ) +
                   theme_bw(base_size = 12) +
                   geom_text(size = 4, position = position_stack(vjust = 0.5),fontface="bold", color="black") +
                   scale_color_viridis(discrete = T, option = "D") +
                   scale_y_continuous(labels = scales::percent) +
                   theme(plot.title=element_text(size=16,  hjust=0.5, color="blue",margin=margin(5,0,5,0))) +
                   #theme(plot.subtitle=element_text(size=14,  hjust=0.5, face="italic", color="firebrick")) +
                   theme(legend.title =element_text(size=12))
                 
                 ifelse(length(yearly_media_spend$year)>1, print(ggplot4_multiple_year),print(ggplot4_single_year))
               },
               height=600)
               
               #####################################################################
               ###     5. Look at trends for any continuous variable by year    ####
               ###          and compare each year's trend against the rest      ####
               ###              to detect any obvious data anomalies            ####
               #####################################################################
               # Set input variables:
               # granularity <- "weekly" # Specify the granularity of your input data (choose from "weekly" or "daily")
               # Specify the continuous variable you want to plot trend for
               
               # Set breaks for X axis
               #brks <- if(input$granularity=="weekly") seq(1,53,4) else seq(1,366,14)
               
               # Dynamic warning message: None for this section
               output$var_to_plot_input <- renderUI({
                 textInput('var_to_plot', label = h4('Continuous Variable to Plot',
                                                     tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                                     popify(bsButton("var_to_plot_popover", label = "", icon = icon("question"), style = "info", size = "extra-small"),
                                                            'Continuous Variable to Plot',
                                                            'Input the column name of the continuous variable you want to the see the trend for.')
                 ), value = paid_media_vars[1])
               })
               
               
               # Plot 5
               output$ggplot5 <- renderPlot({
                 ggplot(setorder(eda_input,DATE),aes(x=(if(input$granularity=="weekly") week(DATE) else yday(DATE)))) +
                   geom_line(aes(y=get(input$var_to_plot), colour = as.factor(year(DATE)))) +
                   labs(title = paste("5. Trend of",input$var_to_plot,"by year"),
                        subtitle = "Compare each year's trend against the rest to detect obvious data anomalies",
                        x = (if(input$granularity=="weekly") "week of year" else "day of year"),
                        y = paste(input$var_to_plot),
                        colour = "Year") +
                   theme(plot.title=element_text(size=16, hjust=0.5, colour="blue", margin=margin(5,0,5,0))) +
                   theme(plot.subtitle=element_text(size=14, hjust=0.5, face="italic", color="firebrick")) +
                   gghighlight(year(DATE)>=min(year(DATE))) +
                   scale_x_continuous(breaks = (if(input$granularity=="weekly") seq(1,53,4) else seq(1,366,14))) +
                   facet_wrap(~ as.factor(year(DATE)))
               }, height = 600)
               
               })
  
################################### HyperParameter Selection/Model Run ########################################
  
  output$adstock_curves_samples <- renderPlot({
    adstock <<- input$adstock_selection
   plot_adstock(T)
  })
  
  output$response_curves_samples <- renderPlot({
    plot_saturation(T)
  })
  
  output$model_window_min <- renderUI({
    dateInput('min_date_model_build', label = 'Input start date for model data',
              value = min(dt_input$DATE), min = min(dt_input$DATE), max = max(dt_input$DATE))
  })
  
  output$model_window_max <- renderUI({
    dateInput('max_date_model_build', label = 'Input end date for model data',
              value = max(dt_input$DATE), min = min(dt_input$DATE), max = max(dt_input$DATE))
  })
  
  output$local_hyperparam_sliders_paid <- renderUI({
      lapply(1:length(paid_media_vars), function(i){
        if(input$adstock_selection == 'weibull'){
          splitLayout(
              sliderInput(paste0('medVar_',paid_media_vars[i],'_alphas'),label=div(style = 'font-size:12px',paste0(paid_media_vars[i],'_alphas'))
                          , min=0.001, max=3, value = c(0.001,1),step = 0.01),
              sliderInput(paste0('medVar_',paid_media_vars[i],'_gammas'),label=div(style = 'font-size:12px',paste0(paid_media_vars[i],'_gammas'))
                          , min=0, max=3, value = c(0.3,1),step = 0.01),
              sliderInput(paste0('medVar_',paid_media_vars[i],'_shapes'),label=div(style = 'font-size:12px',paste0(paid_media_vars[i],'_shapes'))
                        , min=0, max=1, value = c(0.3,1),step = 0.01),
              sliderInput(paste0('medVar_',paid_media_vars[i],'_scales'),label=div(style = 'font-size:12px',paste0(paid_media_vars[i],'_scale'))
                        , min=0, max=1, value = c(0.1,0.4),step = 0.01)
        )}
        else if(input$adstock_selection == 'geometric'){
          splitLayout(
            sliderInput(paste0('medVar_',paid_media_vars[i],'_alphas'),label=div(style = 'font-size:12px',paste0(paid_media_vars[i],'_alphas'))
                        , min=0, max=3, value = c(0.5,3),step = 0.01),
            sliderInput(paste0('medVar_',paid_media_vars[i],'_gammas'),label=div(style = 'font-size:12px',paste0(paid_media_vars[i],'_gammas'))
                        , min=0, max=1, value = c(0.5,1),step = 0.01),
            sliderInput(paste0('medVar_',paid_media_vars[i],'_thetas'),label=div(style = 'font-size:12px', paste0(paid_media_vars[i],'_thetas'))
                        , min=0, max=1, value = c(0.1,0.4),step = 0.01)
        )
      }
    })
  })
  
  output$local_hyperparam_sliders_organic <- renderUI({
    if(length(organic_vars) > 0){
    lapply(1:length(organic_vars), function(i){
      if(input$adstock_selection == 'weibull'){
        splitLayout(
          sliderInput(paste0('medVar_',organic_vars[i],'_alphas'),label=div(style = 'font-size:12px',paste0(organic_vars[i],'_alphas'))
                      , min=0.001, max=3, value = c(0.001,1),step = 0.01),
          sliderInput(paste0('medVar_',organic_vars[i],'_gammas'),label=div(style = 'font-size:12px',paste0(organic_vars[i],'_gammas'))
                      , min=0, max=3, value = c(0.3,1),step = 0.01),
          sliderInput(paste0('medVar_',organic_vars[i],'_shapes'),label=div(style = 'font-size:12px',paste0(organic_vars[i],'_shapes'))
                      , min=0, max=1, value = c(0.3,1),step = 0.01),
          sliderInput(paste0('medVar_',organic_vars[i],'_scales'),label=div(style = 'font-size:12px',paste0(organic_vars[i],'_scale'))
                      , min=0, max=1, value = c(0.1,0.4),step = 0.01)
        )}
      else if(input$adstock_selection == 'geometric'){
        splitLayout(
          sliderInput(paste0('medVar_',organic_vars[i],'_alphas'),label=div(style = 'font-size:12px',paste0(organic_vars[i],'_alphas'))
                      , min=0, max=3, value = c(0.5,3),step = 0.01),
          sliderInput(paste0('medVar_',organic_vars[i],'_gammas'),label=div(style = 'font-size:12px',paste0(organic_vars[i],'_gammas'))
                      , min=0, max=1, value = c(0.5,1),step = 0.01),
          sliderInput(paste0('medVar_',organic_vars[i],'_thetas'),label=div(style = 'font-size:12px', paste0(organic_vars[i],'_thetas'))
                      , min=0, max=1, value = c(0.1,0.4),step = 0.01)
        )
      }
    })
    }
  })
  
  observeEvent(input$detect_cores, {
    output$core_count <- renderText({
      cores <- {registerDoSEQ(); detectCores()}
      paste0(toString(cores),' total cores')
    })
  })
  
  output$prophet_country <- renderUI({
    if(isTRUE(input$prophet_enable_checkbox)){
    fluidRow(column(width=4,
    textInput('country', label = h4("Country\'s Alpha-2 Code ",
                                    tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                    bsButton("country_popover", label = "", icon = icon("question"), style = "info", size = "extra-small")
    ), value = ''),
    #inserts link + text popover
    bsPopover(id = 'country_popover', title = 'Country Code Input', 
              content = paste0('Input the Alpha-2 country code of the region you are measuring. To find the code view the ',
                               a('wiki page', href = 'https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2', target = '_blank')), 
              placement = 'right', trigger = 'focus', options = list(container = 'body'))
    ))
  }})
  
  output$prophet_enable <- renderUI({
    if(isTRUE(input$prophet_enable_checkbox)){
      prophet_options <- c('trend','season','holiday','weekday')
      lapply(1:length(prophet_options),function(i){
        checkboxInput(paste0('prophet_option_',prophet_options[i])
                      , label = div(paste0('Enable Prophet ', prophet_options[i], ' decomposition?'),style = 'font-size:12px;'), value = T)
        
      })
    }
  })
  
  output$prophet_signs <- renderUI({
    if(isTRUE(input$prophet_enable_checkbox)){
      prophet_options <- c('trend','season','holiday','weekday')
      lapply(1:length(prophet_options),function(i){
        if(isTRUE(input[[paste0('prophet_option_',prophet_options[i])]])){
          radioButtons(paste0('prophet_sign_',prophet_options[i]), label = div(paste0('Expected Effect Sign for ', prophet_options[i]),style = 'font-size:12px;'),
                      choices = c('default','positive','negative'), selected = 'default', inline = T)
        }
      })
    }
  })
  
  output$calibration_file <- renderUI({
    if(isTRUE(input$enable_calibration)){
      fileInput('calibration_file', label = 'Input CSV file with experiment data for calibration', accept = '.csv')
    }
  })
  
  output$calib_file_date_format <- renderUI({
    if(isTRUE(input$enable_calibration)){
      textInput('calib_date_format_var',label = h4('Input DATE format',tags$style(type = 'text/css','#q2{vertical-align:top;}'),
                                             bsButton('date_format_popover',label = '', icon = icon('question'), style = 'info',size = 'extra-small')
      ),value = '%Y-%m-%d')
    }
  })
  
  output$lift_calib_tbl <- renderDataTable({
    if(isTRUE(input$enable_calibration)){
      file <- input$calibration_file
      ext <- tools::file_ext(file$datapath)
      validate(need(ext == 'csv', 'Please upload a csv file for calibration with experiments'))
      calib_data <<- fread(file$datapath) #save dt_input as global var within server function
      datatable(calib_data, options = list(scrollX = T, scrollCollapse = T, lengthChange = F, sDom = 't'))
    }
  })
  
  observeEvent(input$finalize_hyperparams, {
    hyperparameters <<- list()
    if(input$adstock_selection == 'weibull'){
      lapply(1:length(paid_media_vars), function(i){
        assign(paste0(paid_media_vars[i],'_alphas'), c(input[[paste0('medVar_',paid_media_vars[i],'_alphas')]][1]
               ,input[[paste0('medVar_',paid_media_vars[i],'_alphas')]][2]),envir = .GlobalEnv)
        assign(paste0(paid_media_vars[i],'_gammas'), c(input[[paste0('medVar_',paid_media_vars[i],'_gammas')]][1]
               ,input[[paste0('medVar_',paid_media_vars[i],'_gammas')]][2]),envir = .GlobalEnv)
        assign(paste0(paid_media_vars[i],'_shapes'), c(input[[paste0('medVar_',paid_media_vars[i],'_shapes')]][1]
               ,input[[paste0('medVar_',paid_media_vars[i],'_shapes')]][2]),envir = .GlobalEnv)
        assign(paste0(paid_media_vars[i],'_scales'), c(input[[paste0('medVar_',paid_media_vars[i],'_scales')]][1]
               ,input[[paste0('medVar_',paid_media_vars[i],'_scales')]][2]),envir = .GlobalEnv)
      })
      if(length(organic_vars > 0)){
      lapply(1:length(organic_vars), function(i){
        assign(paste0(organic_vars[i],'_alphas'), c(input[[paste0('medVar_',organic_vars[i],'_alphas')]][1]
                                                       ,input[[paste0('medVar_',organic_vars[i],'_alphas')]][2]),envir = .GlobalEnv)
        assign(paste0(organic_vars[i],'_gammas'), c(input[[paste0('medVar_',organic_vars[i],'_gammas')]][1]
                                                       ,input[[paste0('medVar_',organic_vars[i],'_gammas')]][2]),envir = .GlobalEnv)
        assign(paste0(organic_vars[i],'_shapes'), c(input[[paste0('medVar_',organic_vars[i],'_shapes')]][1]
                                                       ,input[[paste0('medVar_',organic_vars[i],'_shapes')]][2]),envir = .GlobalEnv)
        assign(paste0(organic_vars[i],'_scales'), c(input[[paste0('medVar_',organic_vars[i],'_scales')]][1]
                                                       ,input[[paste0('medVar_',organic_vars[i],'_scales')]][2]),envir = .GlobalEnv)
      })
      }
      hyps <<- c('alphas','gammas','shapes','scales')
      vals <<- list()
      names_l <<- list()
      lapply(1:length(hyps), function(k){
        lapply(1:length(ls(envir = .GlobalEnv)[which(grepl(hyps[k],ls(envir = .GlobalEnv))!=0)]), function(i){
          new_val <<- eval(parse(text=(ls(envir = .GlobalEnv)[which(grepl(hyps[k], ls(envir = .GlobalEnv)) != 0)][i])))
          vals[[length(vals)+1]] <<- new_val
          names_val <<- ls(envir = .GlobalEnv)[which(grepl(hyps[k],ls(envir = .GlobalEnv)) != 0)][i]
          names_l[[length(names_l)+1]] <<- names_val
      })
   })
      names(vals) <- names_l
      hyperparameters <<- vals
      
    }else if(input$adstock_selection == 'geometric'){
      lapply(1:length(paid_media_vars), function(i){
        assign(paste0(paid_media_vars[i],'_alphas'), c(input[[paste0('medVar_',paid_media_vars[i],'_alphas')]][1]
               ,input[[paste0('medVar_',paid_media_vars[i],'_alphas')]][2]),envir = .GlobalEnv)
        assign(paste0(paid_media_vars[i],'_gammas'), c(input[[paste0('medVar_',paid_media_vars[i],'_gammas')]][1]
               ,input[[paste0('medVar_',paid_media_vars[i],'_gammas')]][2]),envir = .GlobalEnv)
        assign(paste0(paid_media_vars[i],'_thetas'), c(input[[paste0('medVar_',paid_media_vars[i],'_thetas')]][1]
               ,input[[paste0('medVar_',paid_media_vars[i],'_thetas')]][2]),envir = .GlobalEnv)      
    })
      if(length(organic_vars) > 0){
      lapply(1:length(organic_vars), function(i){
        assign(paste0(organic_vars[i],'_alphas'), c(input[[paste0('medVar_',organic_vars[i],'_alphas')]][1]
                                                       ,input[[paste0('medVar_',organic_vars[i],'_alphas')]][2]),envir = .GlobalEnv)
        assign(paste0(organic_vars[i],'_gammas'), c(input[[paste0('medVar_',organic_vars[i],'_gammas')]][1]
                                                       ,input[[paste0('medVar_',organic_vars[i],'_gammas')]][2]),envir = .GlobalEnv)
        assign(paste0(organic_vars[i],'_thetas'), c(input[[paste0('medVar_',organic_vars[i],'_thetas')]][1]
                                                       ,input[[paste0('medVar_',organic_vars[i],'_thetas')]][2]),envir = .GlobalEnv)      
      })
      }
      hyps <<- c('alphas','gammas','thetas')
      vals <<- list()
      names_l <<- list()
      lapply(1:length(hyps), function(k){
        lapply(1:length(ls(envir = .GlobalEnv)[which(grepl(hyps[k],ls(envir = .GlobalEnv))!=0)]), function(i){
          new_val <<- eval(parse(text=(ls(envir = .GlobalEnv)[which(grepl(hyps[k], ls(envir = .GlobalEnv)) != 0)][i])))
          vals[[length(vals)+1]] <<- new_val
          names_val <<- ls(envir = .GlobalEnv)[which(grepl(hyps[k],ls(envir = .GlobalEnv)) != 0)][i]
          names_l[[length(names_l)+1]] <<- names_val
    })
      }) 
      names(vals) <<- names_l
      hyperparameters <<- vals
    }
    }
    )
  
  observeEvent(input$finalize_hyperparams,{
    cores <<- NULL
    activate_prophet <<- NULL
    prophet_vars <<- c()
    prophet_signs <<- c()
    prophet_country <<- c()
    dt_calibration <<- NULL
    if(exists('calib_data') == F){calib_data <<- NULL}
    if((is.null(isolate(input$cores_used)) == F) &
       (isolate(input$cores_used) > 0) &
       (isolate(input$min_date_model_build < isolate(input$max_date_model_build))) &
       (is.null(isolate(input$prophet_enable_checkbox)) == F) &
       ((isTRUE(isolate(input$enable_calibration)) & (is.null(isolate(input$calibration_file)) == FALSE) & 
          (length(intersect(c('channel','liftStartDate','liftEndDate','liftAbs'), colnames(calib_data))) == 4)) || 
         (isTRUE(isolate(input$enable_calibration)) == FALSE))
       ){
      cores <<- isolate(input$cores_used)
      nevergrad_algo <<- "TwoPointsDE"
      window_start <<- isolate(input$min_date_model_build)
      window_end <<- isolate(input$max_date_model_build)
      if(isolate(input$prophet_enable_checkbox) == TRUE){
        prophet_country <<- isolate(input$country)
        if(isolate(input$prophet_option_trend) == TRUE){prophet_vars <<- c(prophet_vars, 'trend')}
        if(isolate(input$prophet_option_holiday) == TRUE){prophet_vars <<- c(prophet_vars,'holiday')}
        if(isolate(input$prophet_option_season) == TRUE){prophet_vars <<- c(prophet_vars,'season')}
        if(isolate(input$prophet_option_weekday) == TRUE){prophet_vars <<- c(prophet_vars, 'weekday')}
        if(isolate(input$prophet_option_trend) == TRUE){prophet_signs <<- c(prophet_signs, isolate(input$prophet_sign_trend))}
        if(isolate(input$prophet_option_holiday) == TRUE){prophet_signs <<- c(prophet_signs,isolate(input$prophet_sign_holiday))}
        if(isolate(input$prophet_option_season) == TRUE){prophet_signs <<- c(prophet_signs,isolate(input$prophet_sign_season))}
        if(isolate(input$prophet_option_weekday) == TRUE){prophet_signs <<- c(prophet_signs, isolate(input$prophet_sign_weekday))}
        
      }
      if(isTRUE(isolate(input$enable_calibration)) & (is.null(isolate(input$calibration_file)) == FALSE) &
         (length(intersect(c('channel','liftStartDate','liftEndDate','liftAbs'), colnames(calib_data))) == 4)){
        dt_calibration <<- calib_data
        dt_calibration <<- dt_calibration[,DATE:=as.Date(get('liftStartDate'), isolate(input$calib_date_format_var))]
        dt_calibration <<- dt_calibration[,DATE:=as.Date(get('liftEndDate'), isolate(input$calib_date_format_var))]
        dt_calibration$liftStartDate <<- as.Date(gsub('00','20',dt_calibration$liftStartDate))
        dt_calibration$liftEndDate <<- as.Date(gsub('00','20',dt_calibration$liftEndDate))
      }


      showModal(modalDialog(
        title = "Input_success - Please click anywhere on the screen to proceed",
        easyClose = TRUE,
        footer = NULL
      ))
    }else{
      rm(cores, envir = .GlobalEnv)
      rm(prophet_vars, envir = .GlobalEnv)
      rm(prophet_signs, envir = .GlobalEnv)
      rm(prophet_country, envir = .GlobalEnv)
      rm(dt_calibration, envir = .GlobalEnv)
      showModal(modalDialog(
        title = "Input failed. Please ensure all fields have proper input per tooltip guiance and try again",
        easyClose = TRUE,
        footer = NULL
      ))
    }
  })
  
  observeEvent(input$run_model, {
    iterations <<- input$set_iter
    adstock <<- input$adstock_selection
    trials <<- input$set_trials
    cores <<- input$cores_used
    withCallingHandlers({
      message('Preparing to run model...')
      shinyjs::html("model_gen_text", "")
      if(!dir.exists(paste0(input$dest_folder,'plots'))){dir.create(file.path(paste0(input$dest_folder,'plots')))}
      if(is.null(dt_calibration)){
        robyn_object <<- paste0(input$dest_folder,'plots/Robyn.RDS')
        InputCollect <<- robyn_inputs(dt_input = dt_input
                                     , dt_holidays = dt_holidays
                                     , hyperparameters = hyperparameters
                                     , dt_calibration = NULL
                                     , date_var = date_var
                                     , dep_var = dep_var
                                     , dep_var_type = dep_var_type
                                     , prophet_vars = prophet_vars
                                     , prophet_signs = prophet_signs
                                     , prophet_country = prophet_country
                                     , context_vars = context_vars
                                     , context_signs = context_signs
                                     , paid_media_vars = paid_media_vars
                                     , paid_media_signs = paid_media_signs
                                     , paid_media_spends = paid_media_spends
                                     , organic_vars = organic_vars
                                     , organic_signs = organic_signs
                                     , factor_vars = factor_vars
                                     , cores = cores
                                     , window_start = window_start
                                     , window_end = window_end
                                     , adstock = adstock
                                     , iterations = iterations
                                     , trials = trials
                                     )
        
      }else{
        robyn_object <<- paste0(input$dest_folder,'plots/Robyn.RDS')
        InputCollect <<- robyn_inputs(dt_input = dt_input
                                     , dt_holidays = dt_holidays
                                     , hyperparameters = hyperparameters
                                     , dt_calibration = dt_calibration
                                     , date_var = date_var
                                     , dep_var = dep_var
                                     , dep_var_type = dep_var_type
                                     , prophet_vars = prophet_vars
                                     , prophet_signs = prophet_signs
                                     , prophet_country = prophet_country
                                     , context_vars = context_vars
                                     , context_signs = context_signs
                                     , paid_media_vars = paid_media_vars
                                     , paid_media_signs = paid_media_signs
                                     , paid_media_spends = paid_media_spends
                                     , organic_vars = organic_vars
                                     , organic_signs = organic_signs
                                     , factor_vars = factor_vars
                                     , cores = cores
                                     , window_start = window_start
                                     , window_end = window_end
                                     , adstock = adstock
                                     , iterations = iterations
                                     , trials = trials
        )
        
      }
      
      OutputCollect <<- robyn_run(
        InputCollect = InputCollect # feed in all model specification  # plots will be saved in the same folder as robyn_object
        , plot_folder = robyn_object
        , pareto_fronts = 3
        , plot_pareto = TRUE
        , ui = TRUE
      )
      
      },
    message = function(m) {
      shinyjs::html(id = "model_gen_text", html = paste0(m$message, '<br>'), add = TRUE)
    }
    )

      showModal(modalDialog(
      title = "Models Generated Succesfully - Please proceed to the Model Selection Tab",
      easyClose = TRUE,
      footer = NULL)
    )
    
  })
  
################################### Model Selection tab server functionality ##################################
  output$pParFront <- renderPlot({
    OutputCollect$UI$pParFront
  })
  
  output$plots_folder <- renderUI({
    textInput('folder', label = "Directory containing plots", value = ifelse(exists('OutputCollect$plot_folder'),get('OutputCollect$plot_folder'),'Input Folder of Existing Model Output'))
  })
    
  
  output$pareto_front_tbl <- renderDataTable({
    dat <-OutputCollect$UI$pParFront$data[robynPareto <= 3,]
    dat$rsq_train <- round(dat$rsq_train, digits = 4)
    dat <- dat[order(-rsq_train),]
    dat <- dat[,c('solID','rsq_train','nrmse','decomp.rssd')]
    datatable(dat, rownames = F, options = list(scrollX = T, scrollY = 200, paging = F, sDom = 't'))
  })

  output$model_selection_info <- renderTable({
    req(input$plot_click)
    nearPoints(OutputCollect$UI$pParFront$data, 
      input$plot_click, xvar = "nrmse", yvar = "decomp.rssd", max = 1)[,c('solID','rsq_train')]
    })
  
  observeEvent(input$save_model,{
    if((is.null(isolate(input$plot))==F)&(input$plot %in% OutputCollect$resultHypParam$solID)){
    robyn_object <<- paste0('/',input$folder,'/',gsub(':','.',as.character(Sys.time())),'_solID_',input$plot,'.Rdata')
    robyn_save(robyn_object = robyn_object, select_model = input$plot, InputCollect = InputCollect, OutputCollect = OutputCollect)
      showModal(modalDialog(
        title = paste0('solID - ',input$plot,' saved successfully'),
        easyClose = TRUE,
        footer = NULL
      ))
    }else{
      showModal(modalDialog(
        title = 'Either no solID entered, or solID does not exist. Please try again.',
        easyClose = TRUE,
        footer = NULL
      ))
    }
  })
  
  observeEvent(input$run_model,{
    output$pParFront <- renderPlot({
      OutputCollect$UI$pParFront
    })
    output$pareto_front_tbl <- renderDataTable({
      dat <- OutputCollect$UI$pParFront$data[robynPareto <= 3,]
      dat$rsq_train <- round(dat$rsq_train, digits = 4)
      dat <- dat[order(-rsq_train),]
      dat <- dat[,c('solID','rsq_train','nrmse','decomp.rssd')]
      datatable(dat, rownames = F, options = list(scrollX = T, scrollY = 200, paging = F, sDom = 't'))
  })
  })
  
  observeEvent(input$load_charts,{
    #### OUTPUT RECOMMENDATIONS MESSAGING ############
    
    #overall error messaging
    plotMediaShareLoop <- OutputCollect$xDecompAgg[(solID==input$plot & rn %in% paid_media_vars),]
    
    rsq_train_plot <- plotMediaShareLoop[, round(unique(rsq_train),4)]
    nrmse_plot <- plotMediaShareLoop[, round(unique(nrmse),4)]
    decomp_rssd_plot <- plotMediaShareLoop[, round(unique(decomp.rssd),4)]
    mape_lift_plot <- plotMediaShareLoop[, round(unique(mape),4)]
    
    gen_message <- paste(
      paste0('The first metric we use to determine the fit of the model is ',a('R-Squared value',href='https://en.wikipedia.org/wiki/Coefficient_of_determination',target='_blank')),
      'At a high level, R-squared measures the proportion of the variance in the dependent variable that is explained by changes in the independent variables. For example, an R-squared value of 0.82 would mean that 82% of the variation in the dependent variable is explained by the independent variables.',
      paste0('In solID - ', input$plot,' the <b>R-squared value is - ', rsq_train_plot, '</b>. While it is often the case that a modeler should strive for a high R-squared, there is no exact goal-value that it needs to be above in order to be an acceptable model, but a common rule of thumb is less than 0.8 is not good, between 0.8 and 0.9 may be the best possible in some cases, but r-squared higher than 0.9 is ideal. That said, models with low R-squared values can likely be improved upon. Common ways to address this are through having a more comprehensive set of independent variables. In other words, there are opportunities to split up larger paid media channels, and include additional baseline (non-media) variables that may explain portions of the outcomes. Consider exploring the guidance on baseline and paid media variables included on the Data Input tab to find some ideas.')
      , sep = '<br><br>')
    
    calib_message <- paste(
      paste0('Since we are calibrating our model with data from randomized control trial or geo based experiments, Robyn also aims to minimize the absolute error of the channels represented in these experiements during the period of the experiment. Minimizing this error can significantly help the believability of the model. The metric we use to calculate this error is mape.lift, or ',a('Mean Absolute Percent Error of Lift/Experimental Results', href = 'https://en.wikipedia.org/wiki/Mean_absolute_percentage_error',target = '_blank')),
      paste0('Similar to other measures of error, we look at the differences between observed and predicted values and aim to minimize that. In this case, the <b>Mape.lift is - ',mape_lift_plot,'</b>. The closer this result is to zero, the better as that indicates no difference between the calibration data and the model output.'),
      sep = '<br><br>'
    )
    
    final_gen_message <- ifelse(mape_lift_plot != 0, paste(gen_message,calib_message,sep = '<br><br>'), gen_message)
    
    
    #plot 1 messaging#

    plotWaterfall <- OutputCollect$xDecompAgg[solID==input$plot,]
    
    plotWaterfallLoop <- plotWaterfall[solID == input$plot][order(xDecompPerc)]
    plotWaterfallLoop[, end := cumsum(xDecompPerc)]
    plotWaterfallLoop[, end := 1-end]
    plotWaterfallLoop[, ':='(start =shift(end, fill = 1, type = "lag")
                             ,id = 1:nrow(plotWaterfallLoop)
                             ,rn = as.factor(rn)
                             ,sign = as.factor(ifelse(xDecompPerc>=0, "pos", "neg")))]
    
    high_share <- plotWaterfallLoop[(xDecompMeanNon0Perc > 0.4 & rn %in% context_vars),]
    low_share <- plotWaterfallLoop[abs(xDecompMeanNon0Perc) < 0.01,]
    negative <- plotWaterfallLoop[sign == 'neg' & (rn %in% c('season','weekday','holiday','trend','(Intercept)') == F) ,]
    paid_media_vars <- plotWaterfallLoop[is.na(total_spend) == F,]
    
    generic_message <- 'The first plot looks at the overall decomposition of the model. The larger the bar, the larger the proportion of the effect is explained by changes in that particular variable. For instance, if Facebook_I had a share of 25% of the effect, then we would say that on average, Facebook media is causing 25% of the dependent variable on a given time period. This will change of course when looking at different days and when considering baseline variables as well such as seasonality/trend.'
    
    high_share_message <- ifelse(length(high_share$rn) > 0, 
                                paste('<b>Consideration 1 - High Share of Effect.</b> The variable(s) - ',
                                paste(high_share$rn, collapse = ', '),
                                ' are showing that they have a share of the effect greater than 40%. If this is a non paid-media variable, consider investigating further whether this variable makes sense to include or whether this result makes sense. A case that may occur is a baseline variable that is actually a subset of the dependent variable, and thus should not be used to predict the independent variable as it could be misrepresenting results. If the share of effect vs. share of media spend have a high difference as well that may be concerning.',
                                sep = ''), '')
    
    low_share_message <- ifelse(length(low_share$rn) > 0, 
                          paste('<b>Consideration 2 - Low/No Share of Effect.</b> The variable(s) - ',
                          paste(low_share$rn, collapse = ', '),
                          ', are showing that they have a share of the effect between -0.01% and 0.01%. In other words, they have very limited effect. If this seems highly unlikely please investigate further or consider choosing a solution that makes more business sense.',
                          sep = ''), '')
    
    negative_message <- ifelse(length(negative$rn) > 0 ,
                          paste('<b>Consideration 3 - Negative Effect.</b> The variable(s) - ',
                          paste(negative$rn, collapse = ', '),
                          ', are showing that they have a negative impact on effect. If this seems highly unlikely please investigate further',
                          sep = ''), '')
    
    tot_paid_media_resp_message <- paste('<b>Consideration 4 - Low Paid Media Effect.</b> The Paid Media variable(s) - ',
                                         paste(paid_media_vars$rn,collapse = ', '),
                                         ' represent', 100*round(sum(paid_media_vars$xDecompMeanNon0Perc),2),
                                         '% of the total effect/dependent variable. If this seems too low, consider whether there may be some inappropriate baseline variables included, or there is not enough paid media data included.',
                                         'If this seems too high, consider adding additional baseline variables that may further explain business performance. Throughout these explanatory tabs there should be some additional ideas to investigate.',
                                         'Depending on your marketing spend, it is unlikely that this value should be below 10% or above 90%, but not impossible.',
                                         sep = ' ')
    
    intercept_message <- ifelse(plotWaterfallLoop[rn=='(Intercept)',]$xDecompMeanNon0Perc > 0.3,
                                '<b>Consideration 5 - Large Intercept Effect</b>. - The Intercept is contributing a significant amount towards the dependent variable. Consider adding in additional baseline variables that may help better explain the variation in the dependent variable.'
                                ,'')
    
    no_consid_message <- ifelse(high_share_message=='' & low_share_message == '' & negative_message == '' & tot_paid_media_resp_message == '' & intercept_message == '',
                                'No specific consideration callouts in this section, please proceed to further considerations.','')
    
    plot1_message <- c(generic_message,high_share_message,low_share_message,negative_message,tot_paid_media_resp_message,intercept_message,no_consid_message)
    plot1_message <- paste(plot1_message[which(plot1_message!='')],collapse = '<br><br>')
    
    #Plot2_message
    
    plot2_tab <- OutputCollect$xDecompVecCollect[solID == input$plot,]
    plot2_tab$error <- (plot2_tab$depVarHat/plot2_tab$dep_var)-1
    plot2_tab$error_abs <- abs(plot2_tab$error)
    plot2_tab_top10 <- plot2_tab[order(plot2_tab$error_abs, decreasing = T),][1:10,]
    
    plot2_tab$month <- floor_date(plot2_tab$ds, unit = 'month') 
    plot2_monthly <- plot2_tab %>% 
                      group_by(month) %>% 
                      summarize(err = sum(abs(dep_var/depVarHat - 1))/n())
    plot2_monthly_top10 <- plot2_monthly[order(plot2_monthly$err,decreasing = T),][1:10,]
    
    plot2_tab$year <- floor_date(plot2_tab$ds, unit = 'year') 
    plot2_yearly <- plot2_tab %>% 
      group_by(year) %>% 
      summarize(err = sum(abs(dep_var/depVarHat - 1))/n())
    plot2_yearly_top10 <- plot2_yearly[order(plot2_yearly$err,decreasing = T),]
        
   plot2_message_1 <- paste('When considering the fit of your model, it can be useful to see how over time the model fit looks. For example,',
    'you may uncover that specific time periods (e.g. promotional periods) have high errors. In that case you could consider adding a baseline variable or splitting media in a way that better represents those periods. ',
    'Another case would be when the model does not fit well for multiple time periods. This may be commonly seen around March 2020, when COVID caused huge changes to supply and demand globally overnight.',
    paste0('In this case, consider reading the article ', a('Adjusting MMM for Unexpected Events', href = 'https://www.facebook.com/business/news/insights/5-ways-to-adjust-marketing-mix-models-for-unexpected-events', target= '_blank')),
    paste0('For solID - ', input$plot, ' the below readouts will show the time periods where the model had this largest errors vs. its predicted value. As you parse through these consider how you may be able to better account for underlying factors that correspond to these.'),
    sep = '<br><br>')
   
   tbl_html_funct_2col <- function(df,headers = c('date','absolute_error')){ 
     df <- as.data.frame(df)
     html_msg_1 <- '<table style="width:50%">'
     html_msg_2 <- paste0('<tr>',paste('<th>',headers,'</th>',collapse = '',sep =''),'</tr>')
     html_rows <- ''
     for(i in 1:nrow(df)){
       html_rows <- paste0(html_rows,
         paste0('<tr><td>',df[i,headers[1]],'</td><td>',paste0(100*round(df[i,headers[2]],3),'%'),'</td></tr>')
       )
     }
     html_msg_4 <- '</table>'
     return(paste0(html_msg_1,html_msg_2,html_rows,html_msg_4))
   }
   
   plot2_message_2 <- paste(plot2_message_1, '<b>Indv. Time Periods with the largest error</b>',
                            tbl_html_funct_2col(plot2_tab_top10,c('ds','error')),
                            '<b>Months with the largest error</b>',
                            tbl_html_funct_2col(plot2_monthly_top10,c('month','err')),
                            '<b>Years with the largest error</b>',
                            tbl_html_funct_2col(plot2_yearly_top10,c('year','err')),
                            'If there are periods/days that are seeing large errors but may be explainable by something concrete rather than the natural variation, consider adding a variable to describe that relationship to the model.',
                            sep = '<br><br>'
                            )
    
  #plot3_message
   
   plot3_message_1 <- paste('In Robyn, one of the variables that is being minimized is decomp.rssd, which is a measure of how far apart the share of paid media spend, and share of paid media effect are. In other words, we want to optimize away from models that have highly disparate spend & effect shares because it does not make logical sense for the business to dramatically change their historical spend patterns.',
                            'In this chart, we examine for each paid media variable the average share of spend and the average share of effect as well as the <b>ROI which is calculated as (mean effect / mean spend).</b>',
                            'If your dependent variable is revenue, this is straightforward. On average, if you spend an additional dollar on the media channel in question, you would get ROI dollars back in revenue. If your dependent variable is more along the lines of conversions, the ROI value is not as straightforward. In this case, the ROI can be interpreted as the average number of conversions generated for an additional dollar spent on that channel. In this case, it would make most sense that the value is between 0 and 1.',
                            'For channels where the proportion of spend is very low, it may be more likely that ROIs reported are less believable, since they may not hold up as well through extrapolation. Generally, extrapolation beyond a certain % increase is not very reliable, so if your channel had 2% of spend increasing to 10% of spend is a 500% increase which is quite hard to extrapolate in a believable way since there is likely little data at that level of spend.',
                            'One thing to remember - If your dependent variable corresponds to conversions and not revenue the ROI will be conversions per dollar spent, not revenue per dollar spent.',
                            sep = '<br><br>')
   
  #plot4_message
   plot4_message_1 <- paste('Cost-Response curves, Response Curves, or Diminishing Returns Curves are one of the key outputs of Marketing Mix Models. With them, Marketers can understand at what their optimal investment level in a given channel is, or when used in aggregate, how to make overall budget investment decisions.',
                            'A key principle that these Response curves follow is the theory of diminishing returns. This means that at a certain point we expect the return on investment of ($X+1 - $X) < ($X - $X-1) or in other words, the profitability of any given channel will eventually reach a point where it is no longer an acceptable return on investment for a business. Typically, when ROI < 1.',
                            'These Response Curves also have hyperparameters - Alpha and Gamma. These hyperparameters will effect the shape of the response curve. The higher the <b>Alpha</b> hyperparameter, the more S-shape the curve will be. The lower the Alpha, the more C-shape the response-curve will be. Traditionally C-shape was more used. while its simpler, it means the first dollar spent has always the highest marginal ROI, which is often not very intuitive. Using the hill-function, Robyn can switch to S-curves, meaning starting slow, and reaching higher marginal ROI somewhere in the middle, then saturating which is a more intuitive option. For <b>Gamma</b> hyperparameters, the higher the value the higher the inflection point will be, or in other words, the higher the level of investment that the channel will start hitting diminishing returns on investment. A lower Gamma means that the channel will reach a saturation point at a lower level of investment.',
                            'Please look at the charts here to get a better understanding of how these response curves may behave. Shortly you will have response curves of your own generated!',
                            sep = '<br><br>'
   )
   
   plot4_tbl_alphas <-OutputCollect$resultHypParam[solID == input$plot] %>% select(contains('alpha'))
   plot4_tbl_gammas <- OutputCollect$resultHypParam[solID == input$plot] %>% select(contains('gamma'))
   plot4_alphas_message <- paste(
     paste0('In solID - ', input$plot, ' we see that the paid media variables have the following <b>Alpha values</b>'),
     paste0(colnames(plot4_tbl_alphas),' - ', round(plot4_tbl_alphas,3) ,collapse = '<br>'),
     sep = '<br><br>'
   )
   plot4_gammas_message <- paste(
     paste0('In solID - ', input$plot, ' we see that the paid media variables have the following <b>Gamma values</b>'),
     paste0(colnames(plot4_tbl_gammas),' - ', round(plot4_tbl_gammas,3) ,collapse = '<br>'),
     sep = '<br><br>'
   )
   plot4_message_2 <- paste('Much of the analyst interpretation here is evaluating whether these curves look realistic. For example, curves that show no point of diminishing returns may make sense if the investment is still relatively small, or the channel is new, but as the investment continues to rise there should be some declines in efficiency. Additionally, continue to investigate media channels that appear to have very low effect compared to their spend level, or the reverse.',
                            'Use your best judgement to determine what seems realistic here, and identify any trends across model solutions about individual media channels that seem to arise.',
                            'One final point is to remember that the further you get from your historical mean spend, the higher the chance of performance that is different than what the response curves predict.',
                            sep = '<br><br>'
   )
   plot_4_final_message <- paste(plot4_message_1,plot4_alphas_message,plot4_gammas_message,plot4_message_2,sep = '<br><br>')
   
   #plot5_message
   
   plot5_message_1 <- paste('In this plot we examine the adstock decay rates for each paid media channel. For a quick refresher, the adstock defines how much effect of media that occurs in time period X is carried over into time period X+1, since we know that not all impact from an advertisement has to occur on the day it is delivered.',
                            'Much of the interpretation of this plot as well is determining whether or not these results make intuitive sense. For example, if results are showing that a channel carries over a very large amount of its effect, then that may something worth exploring further. Especially if that channel is one that we usually consider more lower funnel.',
                            'What would be considered a high or low adstock will also change depending on the time granularity of your data, so be sure to consider that as well as you interpret these results.',
                            sep = '<br><br>')
   
   #plot6_message
   plot6_message_1 <- paste('In this plot we examine in a way similar to plot 2 Actual vs. Predicted results a plot of the measure of the residuals for each prediction with the size of the prediction on the x-axis. Given that we would hope our predicted values have an error of 0, we would also hope that our errors when comparing predicted values against the actual values should be randomly distributed around 0. If we notice areas where the residuals have a clear trend, that is cause for concern about the validity of the model, and may be representative of heteroskedasticity which may speak to the believability of the fit of the model in certain periods as being better than others in a biased way. An example could be a period where sales and spend drastically increase, and afterwards the residuals are much larger representing unequal variance of the errors. Consider addressing this using additional baseline/non-media variables.',
                            'If you do see that the band around the blue average line here does not include the value 0 for portion of your results, it may be worth further exploring those data points to see if there is some bias in the model. If it is only for a period or two, then it is likely not too bad, but if there is significant differences over time then it would be cause for concern.',
                            sep = '<br><br>')
   
   #outputs
    output$model_output_expl_gen <- renderUI({
      fluidRow(
        column(width=6,
                bsButton('model_output_gen_popover', label = 'Interpreting Model Suitability Statistics', style = 'info', size = 'medium'),
                bsPopover(id = 'model_output_gen_popover', title = paste0('Model Suitability Statistics Explanations and Recommendations for solID - ',input$plot),
                          content = final_gen_message,
                         placement = 'bottom', trigger = 'focus', options = list(container = 'body'))
               )
      )
    })
    
    output$model_output_expl_1 <- renderUI({
      fluidRow(column(width = 2,
        bsButton('model_output_plot_1_popover', label = 'Interpreting plot #1 - Waterfall Decomposition', style = 'info', size = 'medium'),
        bsPopover(id = 'model_output_plot_1_popover', title = paste0('Considerations for the Decomposition of solID ',input$plot), 
                  content = plot1_message, 
                  placement = 'bottom', trigger = 'focus', options = list(container = 'body'))),
        column(width = 2, offset = 2,
        bsButton('model_output_plot_2_popover', label = 'Interpreting plot #2 - Actual vs. Predicted Results', style = 'info', size = 'medium'),
        bsPopover(id = 'model_output_plot_2_popover', title = 'Considerations for interpreting Actual vs. Predicted Results', 
                  content = plot2_message_2,
                  placement = 'bottom', trigger = 'focus', options = list(container = 'body'))
      ))})
      output$model_output_expl_2 <- renderUI({
        fluidRow(column(width=2,
          bsButton('model_output_plot_3_popover', label = 'Interpreting plot #3 - Share of Spend vs. Share of Effect', style = 'info', size = 'medium'),
          bsPopover(id = 'model_output_plot_3_popover', title = 'Interpreting ROI and Share of Spend vs. Effect', 
                    content = plot3_message_1, 
                    placement = 'bottom', trigger = 'focus', options = list(container = 'body'))),
          column(width = 2, offset = 2,
          bsButton('model_output_plot_4_popover', label = 'Interpreting plot #4 - Response Curves', style = 'info', size = 'medium'),
          bsPopover(id = 'model_output_plot_4_popover', title = paste0('Interpreting Response Curves of solID ',input$plot), 
                    content =  plot_4_final_message, 
                    placement = 'bottom', trigger = 'focus', options = list(container = 'body')))
        )})
        output$model_output_expl_3 <- renderUI({
          fluidRow(column(width=2,
            bsButton('model_output_plot_5_popover', label = 'Interpreting plot #5 - Adstock decay rates', style = 'info', size = 'medium'),
            bsPopover(id = 'model_output_plot_5_popover', title = paste0('Interpreting Adstock Decay Rates of solID ',input$plot), 
                      content = plot5_message_1, 
                      placement = 'bottom', trigger = 'focus', options = list(container = 'body'))),
            column(width=2,offset=2,
            bsButton('model_output_plot_6_popover', label = 'Interpreting plot #6 - Fitted vs. Residuals', style = 'info', size = 'medium'),
            bsPopover(id = 'model_output_plot_6_popover', title = paste0('Interpreting Fitted Vs. Residual Plots of solID ',input$plot), 
                      content = plot6_message_1, 
                      placement = 'bottom', trigger = 'focus', options = list(container = 'body')))
          )})        
  })
  
  
  observeEvent(input$load_charts, {
    output$load_selection_plot <- renderUI({
      withSpinner(plotOutput('model_selection_img'))
    })
    
    output$model_selection_img <- renderImage({
      filename <- normalizePath(isolate(file.path(input$folder, paste(input$plot, '.png', sep=''))))
      list(src = filename, width = "100%", height = "auto")
      
    }, deleteFile = FALSE)
    
    output$model_summary_tbl <- renderDataTable({
      OutputCollect$xDecompAgg[solID == isolate(input$plot) & !is.na(mean_spend)
                               , .(rn, coef,mean_spend, mean_response, roi_mean
                                   , total_spend, total_response=xDecompAgg, roi_total, solID)]
    })
    }
  )
  
#################################### optimizer tab server functionality #######################################
  output$optimizer_plot <- renderPlot({NULL})

  output$expected_spend <- renderUI({
    if(input$opt_scenario == 'max_response_expected_spend'){
      fluidRow(column(width = 2,
      numericInput('expected_spend_opt',label = h4('Expected Spend in Optimization Period',
                                                tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                                bsButton('expected_spend_popover',label ='', icon = icon("question"), style = "info", size = "extra-small")),step = 1, min = 1, value = 100000),
      bsPopover(id = 'expected_spend_popover', title = 'Expected Spend in Optimization Period',
                content = 'Input your total expected spend for the optimization period in the same currency that the rest of your spend data is in.',
                placement = 'right', trigger = 'focus', options = list(container = 'body'))
      ))
    }
  })

  output$expected_days <- renderUI({
    if(input$opt_scenario == 'max_response_expected_spend'){
      fluidRow(column(width = 2,
                  numericInput('expected_days_opt',label = h4('Expected Days in Optimization Period',
                                                               tags$style(type = "text/css", "#q2 {vertical-align: top;}"),
                                                               bsButton('expected_days_popover',label ='', icon = icon("question"), style = "info", size = "extra-small")),step = 1, min = 1, value = 90),
                  bsPopover(id = 'expected_days_popover', title = 'Expected Spend in Optimization Period',
                            content = 'Input your total expected days for the optimization period. One important nuance - Even if your data is weekly data the input in here should be in days.',
                            placement = 'right', trigger = 'focus', options = list(container = 'body'))
      ))
    }
  })
  
  output$sliders <- renderUI({
    lapply(1:length(paid_media_spends), function(i){
      sliderInput(paste0('medVar_',paid_media_spends[i]),label=div(style = 'font-size:12px',paid_media_spends[i])
                  , min=0, max=3, value = c(0.8,1.2),step = 0.01)})
  })
  
  observeEvent(input$run_opt,{
    output$optimizer_plot <- renderPlot({
      channel_constr_low_list <- unlist(lapply(1:length(paid_media_spends), function(i){isolate(eval(parse(text=paste0('input$medVar_',paid_media_spends[i]))))[1]}))
      channel_constr_up_list <- unlist(lapply(1:length(paid_media_spends), function(i){isolate(eval(parse(text=paste0('input$medVar_',paid_media_spends[i]))))[2]}))
      optim_result <<- isolate(robyn_allocator(InputCollect = InputCollect
                                        ,OutputCollect = OutputCollect# input one of the model IDs in OutputCollect$allSolutions to get optimisation result
                                        ,select_model = isolate(input$solID)
                                        ,scenario = isolate(input$opt_scenario) # c(max_historical_response, max_response_expected_spend)
                                        ,expected_spend = isolate(input$expected_spend_opt) # specify future spend volume. only applies when scenario = "max_response_expected_spend"
                                        ,expected_spend_days = isolate(input$expected_days_opt) # specify period for the future spend volumne in days. only applies when scenario = "max_response_expected_spend"
                                        ,channel_constr_low = c(channel_constr_low_list) # must be between 0.01-1 and has same length and order as paid_media_vars
                                        ,channel_constr_up =  c(channel_constr_up_list) # not recommended to 'exaggerate' upper bounds. 1.5 means channel budget can increase to 150% of current level
                                        ,ui = TRUE))

      title <- paste0("Budget allocator optimum result for model ID ", isolate(input$solID))
      g <- ((optim_result$ui$p13) + (optim_result$ui$p12) / (optim_result$ui$p14) + plot_annotation(
        title = title, theme = theme(plot.title = element_text(hjust = 0.5))
      ))
      g
      })
    
    output$optimizer_tbl <- renderDataTable({
      data.table(optim_result$dt_optimOut)
    })
    
    
  })
}
shinyApp(ui, server)


